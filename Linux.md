# 基础指令

-   (指令) &

    在后台运行

-   ls	

    显示当前目录列表

-   cd dir	

    到达目录dir

-   mkdir dir	

    创建目录dir

-   vim name 

    打开文件name

-   set nu 

    显示行号（在文件内使用）

-   touch name	

    创建文件name

-   rm name	

    删除文件name

-   ll	

    查看文件及目录详情

-   cp [options] source dest	

    将source复制到dest，options是具体复制操作的选项

-   mv [options] source dest	

    将source移动到dest，options是具体移动操作的选项

-   *.xxx	

    相当于对所有.xxx后缀的对象进行操作

-   ..	

    上级目录

-   .	

    当前目录

-   env	

    显示当前用户的环境变量	

-   export [-f/-n/-p] [name] = [val]	

    设置或显示环境变量name的值为val，可以新增、修改、删除环境变量。-f 代表[name]中为函数名称；-n 删除指定的变量（实际上并未删除，只是不输出到后续值令的执行环境中）；-p 列出所有shell赋予程序的环境变量。这种方式事实上不会真的修改，只是会改变当前终端的后续执行环境。

-   $name	

    获取变量name或环境变量name的值

-   pwd	

    （print work directory）用于显示工作目录，得到当前所在目录的绝对路径名称

-   echo xxx	

    将xxx打印显示出来，xxx可以是变量

-   source filename	

    在当前bash环境下读取并执行filename中的命令（也可以使用 . filename ）

-   cd ~	

    家目录

## 编辑操作

shift + g	下拉到最下面

o	插入

wq	保存并退出

# GCC操作

## gcc/g++编译选项

-E	预处理指定源文件，不进行编译

-S	编译指定源文件，但是不进行汇编

-c	编译、汇编指定源文件，但是不进行链接

-o [file1] [file2] / [file2] -o [file1]	将文件file2编译成可执行文件file1

-I(大写的i) dir	指定include包含文件的搜索目录dir

-g	在编译的时候，生成调试信息，该程序可以被调试器调试

-D name	编译的时候指定宏name

-w	不生成任何警告信息

-Wall	生成所有警告信息

-On	“吸氧”，n的取值范围：0~3。编译器的优化选项的4个级别：-O0没有优化，-O1为缺省值（默认），-O3优化级别最高 

-l(小写的L)	在程序编译的时候，指定使用的库

-L	指定编译的时候，搜索库的路径

-fPIC/fpic	生成与位置无关（内存位置）的代码

-shared	生成共享目标文件，通常用在建立共享库时

-std	指定c语言，如：-std=99，gcc默认的方言是GNU C

# 库

## 工作原理

静态库：gcc进行链接时，会把静态库中代码打包到可执行程序中

动态库：gcc进行链接时，动态库的代码不会被打包到可执行程序中

程序启动之后，动态库会被动态加载到内存中，通过ldd（list dynamic dependencies）命令检查动态库依赖关系

Linux定位共享库文件：当系统加载可执行代码时，能够知道其所依赖的库的文件，但是还需要知道绝对路径。此时需要系统的动态载入器来获取该绝对路径。对于elf格式的可执行程序，是由ld-linux.so来完成的，它先后搜索elf文件的DT_RPATH段->环境变量LD_LIBRARY_PATH->/etc/ld.so.cache文件列表->/lib/,/usr/lib目录找到库文件后将其载入内存（不建议使用最后一种方法，因为预置了系统的库文件）

### 修改环境变量的方法

不同目录之间用 : 分隔开

方法一（终端级）：修改当前bash（终端）的环境变量，直接在当前bash中export环境变量

方法二（用户级）：在用户根目录的隐藏文件.bashrc中修改环境变量，在根目录的.bashrc中export环境变量，然后source生效export指令

方法三（系统级）：在系统/etc/profile文件中修改环境变量，export然后再source

### 修改/etc/ld.so.cache

无法直接修改，间接修改通过/etc/ld.so.conf，直接在里面添加环境变量的路径，然后ldconfig。（都在sudo下执行）

## 静态库和动态库的区别

静态库在程序的链接阶段被复制到了程序中；动态库在链接阶段没有被复制到程序中，而实程序在运行时由系统动态加载到内存中供程序调用。

具体而言：

在链接阶段，静态库将被需要的代码链接进去，而动态库只会将一些动态库的信息（比如：名称、地址）链接进去，当程序运行需要的时候再寻找动态库的文件，并把动态库加载到内存中，这样才能使用动态库中的代码。

## 库的好处

1、代码保密；

2、方便部署和分发

## 静态库

### 命名规则

Linux：libxxx.a	lib固定前缀，xxx库的名字，.a固定后缀

Windows：libxxx.lib	lib固定前缀，xxx库额名字，.lib固定后缀

### 静态库的制作

步骤一：gcc获得.o文件，将库文件编译，要在头文件下，或者指定头文件

gcc/g++ -c

步骤二：将.o文件打包，使用ar工具（archive)	

ar rcs libxxx.a xxx.o xxx.o	

r - 将文件插入备存文件中 

c - 建立备存文件 

s - 索引

### 静态库的使用

在程序的源代码中inclue 头文件和调用里面的函数/变量

编译的时候要指定头文件目录和库文件目录、

### 静态库的优缺点

- 优点

  静态库被打包到应用程序中加载速度快

  发布程序无需提供静态库，移植方便

- 缺点

  消耗系统资源，浪费内存

  更新、部署、发布麻烦

  

## 动态库（共享库）

### 命名规则

Linux：libxxx.so	lib：固定前缀	xxx：库的名字	.so：固定后缀	在linux下是一个可执行文件

Windows：libxxx.dll

### 动态库的制作

步骤一：gcc/g++ 编译得到.o文件，得到和位置无关的代码	

gcc -c -fpic/-fPIC xxx.c xxx.c

步骤二：gcc得到动态库

gcc -shared xxx.o xxx.o -o libxxx.so

### 动态库的使用

在程序的源代码中inclue 头文件和调用里面的函数/变量

编译的时候要指定头文件目录和库文件目录

### 动态库优缺点

- 优点

  可以实现进程间资源共享（共享库）

  更新、部署、发布简单

  可以控制何时加载动态库

- 缺点

  加载速度比静态库慢

  发布程序时需要提供依赖的动态库

# Makefile

一个工程中的源文件不计其数，其按类型、功能、模块分别放在若干个目录中，Makefile文件定义了一系列的规则来指定哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译，甚至于进行更复杂的功能操作，因为Makefile文件像一个shell脚本一样，也可以执行操作系统的命令。

## 好处

自动化编译。Makefile一旦写好，只需要一个make命令，整个工程完全自动编译，极大的提高了软件开发的效率。make是一个命令工具，是一个解释Makefile文件中指令的命令工具，一般来说大多数IDE都要这个命令。（Visual C++ : nmake；Linux GNU：make）

## 编写

### 文件命名

makefile 或者Makefile

### 规则

-   一个Makefile文件中可以有一个或者多个规则

    目标…: 依赖…

    ​		命令(shell命令)

    ​		…

    （目标：最终要生成的文件（伪目标除外）；依赖：生成目标所需要的文件或是目标；命令：通过执行命令对依赖操作生成目标（命令前必须tab缩进））

-   其他规则一般都是为第一条规则服务

## 工作原理

-   命令在执行之前，需要检查规则中的依赖是否存在

    如果存在，执行命令

    如果不存在，向下检查其他规则，检查有没有一个规则是用来生成这个依赖的，如果找到了，则执行该规则中的命令

-   检测更新，在执行规则中的命令时，会比较目标和依赖文件的时间

    如果依赖的时间比目标的时间晚，需要重新生成目标

    如果依赖的时间比目标的时间早，目标不需要更新，对应规则中的命令不需要被执行

## 变量

-   自定义变量

    变量名 = 变量值

-   预定义变量

    AR ：归档维护程序的名称，默认值为 ar

    CC ：C编译器的名称，默认值为 cc

    CXX ：C++编译器名称，默认值为 g++

    $自动变量(只能在规则的命令中使用)\begin{cases}\ \$@ ：目标的完整名称 \\ \$< ：第一个依赖文件的名称\\ \$^ ：所有的依赖文件 \end{cases}$

-   获取变量的值

    $(变量名)

## 模式匹配

%：通配符，匹配一个字符串

两个%匹配的是同一个字符串

## 函数

格式：

$(函数名 函数参数…)

例如：

-   $(wildcard PATTERN…)

    功能：获取指定目录下指定类型的文件列表

    参数：PATTERN指的是某个或多个目录下的对应的某种类型的文件，如果有多个目录，一般使用空格间隔

    返回：得到的若干个文件的列表，文件名之间使用空格间隔

    示例：

    $(wildcard \*.c ./sub/\*.c)

    返回格式：a.c b.c c.c d.c e.c f.c

-   $(patsubst \<pattern\>, \<replacement\>,\<text\>)

    功能：查找\<text\>中的单词（单词以“空格”、“tab”或“回车””换行“分隔）是否符合模式\<pattern\>，如果匹配，则以\<replacement\>替换

    \<pattern\>可以包括通配符’%‘，表示任意长度的字符串。如果\<replacement\>中也包含‘%’，那么，\<replacement\>中的这个‘%’将是\<pattern\>中的那个%所代表的字符串。（可以用‘\’来转义，来表示真实含义的‘%’字符)

    返回：函数返回被替换过后的字符串

    示例：

    $(patsubst %.c, %.o, x.c bar.c)

    返回值格式：x.o bar.o

## 伪目标

当不需要生成目标文件时，可将目标文件变成伪目标即可

格式：

.PHONY: 目标

# GDB调试

## GDB

GDB是由GNU软件系统社区提供的调试工具，同GCC配套组成了一套完整的开发环境，GDB是Linux和许多类Unix系统中的标准开发环境

## 功能

1.启动程序，可以按照自定义的要求运行程序

2.可让被调试的程序在所指定的调置的断点处停住（断点可以是条件表达式）

3.当程序被停住时，可以检查此时程序中所发生的事

4.可以改变程序，将一个bug产生的影响修成从而测试其他bug

## 准备工作

通常，在为调试而编译时，我们会关掉编译器的优化选项（‘-o’），并打开调试选项（’-g’）。另外，

‘-wall’在尽量不影响程序行为的情况下选项打开所有warning，也可以发现许多问题，避免不必要的bug。

示例：

gcc -g -Wall progam.c -o progam

‘-g’选项的作用是在可执行文件中加入源代码的信息，比如可执行文件中第几条机器指令对应源代码的第几行，但并不是把整个源文件嵌入到可执行文件中，所以在调试时必须保证gdb能找到源文件

## GDB 命令

-   启动和退出

    gdb 可执行程序

    quit

-   给程序设置参数/获取设置参数

    set args 10 20

    show args

-   查看当前文件代码

    list/l (从默认位置显示)

    list/l 行号 (从指定的行显示)

    list/l 函数名 (从指定的函数显示)

-   查看非当前文件代码

    list/l 文件名：行号

    list/l 文件名：函数名

-   设置显示的行数

    show list/listsize

    set list/listsize 行数

-   gdb使用帮助

    help

-   设置断点

    b/break 行号
    b/break 函数名

    b/break 文件名：行号

    b/break 文件名：函数

-   查看断点

    i/info b/break

-   删除断点

    d/del/delete 断点编号

-   设置断点无效

    dis/disable 断点编号

-   设置断点生效

    ena/enable 断点编号

-   设置条件断点（一般用在循环的位置）

    b/break 断点编号 条件

    示例：

    b/break 10 if i == 5

-   运行GDB程序

    start（程序停在第一行）

    run（遇到断点才停）

-   继续运行，到下一个断电停

    c/continue

-   向下执行一行代码（不会进入函数体）

    n/next

-   变量操作

    p/print 变量名（打印变量值）

    ptype 变量名（打印变量类型）

-   向下单步调试（遇到函数进入函数体）

    s/step

    finish(跳出函数体)

-   自动变量操作

    display num（自动打印指定变量的值）

    i/info display 

    undisplay 编号

-   其他操作

    set var 变量名=变量值

    until（跳出循环）

## 多进程调试

gdb默认只能跟踪一个进程

-   set follow-fork-mode [parent(默认) | child]

    设置调试父进程或者子进程

-   set detach-on-fork [on(默认) | off]

    设置调试模式. on:表示调试当前进程时,其他进程继续运行; off: 其他进程被gdb挂起

-   info inferiors

    查看调试的进程

-   inferiors id

    切换当前调试的进程

-   detach inferiors id

    使进程脱离gdb调试

# C函数

## 文件属性操作函数

-   int access(const char *pathname, int mode)

    判断文件权限或文件是否存在

-   int chmod(const char *filename, int mode)

    修改文件权限

-   int chown(const char *path, uid_t owner, gid_t group)

    修改文件的所有者或者所在组

-   int truncate(const char *path, off_t length)

    缩减或拓展文件的大小

## 目录操作函数

-   int mkdir(const char *pathname, mode_t mode)

    创建目录

-   int rmdir(const char *pathname)

    删除空目录

-   int rename(const char *oldpath, const char *newpath)

    重命名目录

-   int chdir(const char *path)

    修改当前目录的当前路径

-   char *getcwd(char *buf, size_t size)

    获取当前的路径

## 目录遍历函数

-   DIR *opendir(const char *name)

    打开目录

-   struct dirent *readdir(DIR *dirp)

    读取目录

-   int closedir(DIR *dirp)

    关闭目录	

## 文件操作符相关函数

-   int dup(int oldfd)

    复制文件描述符

-   int dup2(int oldfd, int newfd)

    重定向文件描述符，即：将newfd重定向至oldfd的指向，该函数的返回值与newfd相同

-   int fcntl(int fd, int cmd, …/\*arg\*/)

    复制文件描述符

    设置/获取文件的状态标志

    cmd：该函数内定义的一些命令宏

    …：可选参数

## exec函数族

(函数族:一系列具有相同或类似功能的函数的统称)

### 作用

根据指定的文件名找到可执行文件,并用它来取代调用进程的内容.

即:在调用进程内部执行一个可执行文件.

exec函数执行成功后不会返回,因为调用进程的实体,包括代码段,数据段,堆栈都被新内容替代(用户数据区),只留下进程ID等一些表面信息保持原样.只有调用失败了,才会返回-1,从原程序的调用点接着往下执行.

-   int execl(const char *path, const char *arg, …/\*(char \*) NULL\*/)

    path:需要指定的执行的文件的路径或者名称

    arg:是可执行文件所需要的参数列表

    ​	第一个参数没什么作用,一般写可执行程序的名称

    ​	第二个参数开始就是程序执行所需要的参数列表

    ​	参数最后需要以NULL结束

    返回值:

    ​	只有调用失败才会返回-1,否则没有返回值

-   int execlp(const char *file, const char *arg, …/\*(char *) NULL\*/)

    [会到环境变量中查找指定的可执行文件,如果找到了就执行,找不到就执行不成功]

    path:需要指定的执行的文件的文件名

    arg:是可执行文件所需要的参数列表

    ​	第一个参数没什么作用,一般写可执行程序的名称

    ​	第二个参数开始就是程序执行所需要的参数列表

    ​	参数最后需要以NULL结束

    返回值:

    ​	只有调用失败才会返回-1,否则没有返回值

-   int execle(const char *path, const char *arg,…/\*(char *) NULL, char *const envp[]\*/)

-   int execv(const char *path, char *const argv[])

-   int execvp(const char *file, char *const argv[])

-   int execvpe(const char *file, char *const argv[], char *const envp[])

-   int execve(const char *filename, char *const argv[], char *const enp[])

    前6个是标准C库的,最后一个是Linux的

    l(list)	参数地址列表,以空指针结尾

    v(vector)	存有各参数地址的指针数组的地址

    p(path)	按PATH环境变量指定的目录搜索可执行文件

    e(environment)	存有环境变量字符串地址的指针数组的地址

# 进程

## 进程组

-   每个进程组有一个领头进程。进程组是一个或多个进程的集合，通常它们与一组作业相关联，可以接受来自同一终端的各种信号。
-   进程组和会话在进程之间形成了一种两级层次关系：进程组是一组相关进程的集合，会话是一组相关进程组的集合。进程组和会话是为支持shell 作业控制而定义的抽象概念，用户通过shell 能够交互式地在前台或者后台运行命令
-   进程组由一个或多个共享统一进程组标识符（PGID）的进程组成。一个进程组拥有一个进程组首进程，该进程是创建该组的进程，其进程ID为该进程组的ID，新进程会继承其父进程所属的进程组ID
-   进程组拥有一个生命周期，其开始时间为首进程创建组的时刻，结束时间为最后一个成员进程退出组的时刻。一个进程可能会因为终止而退出进程组，也可能会因为加入了另外一个进程组而退出进程组。进程组首进程无需是最后一个离开进程组的成员

## 会话

-   会话是一组进程组的集合。会话首进程是创建该新会话的进程，其进程ID 会成为会话ID。新进程会继承其父进程的会话ID 
-   一个会话中的所有进程共享单个控制终端。控制终端会在会话首进程首次打开一个终端设备时被建立。一个终端最多可能会成为一个会话的控制终端。
-   在任一时刻，会话中的其中一个进程组会成为终端的前台进程组，其他进程组会成为后台进程组。只有前台进程组中的进程才能从控制终端中读取输入。当用户在控制终端中输入终端字符生成信号后，该信号会被发送到前台进程组中的所有成员
-   当控制终端的连接建立起来之后，会话首进程会成为该终端的控制进程

### 进程组、会话操作函数

-   pid_t getpgrp(void)
    -   功能：获取当前进程组ID
-   pid_t getprgid(pid_t pid)
    -   功能：获取指定进程的组ID
-   int setpgid(pid_t pid, pid_t pgid)
    -   功能：设置指定进程的进程组
-   pid_t getsid(pid_t pid)
    -   功能：获取指定的进程的会话ID
-   pid_t setsid(void)
    -   功能：设置当前进程的会话ID

## 守护进程（Daemon Process）

-   守护进程，也就是通常说的Daemon 进程（精灵进程），是Linux中的后台服务进程。它是一个生存期较长的进程，通常独立于控制终端并且周期性地执行某种任务或等待处理某些发生的时间。一般采用以d 结尾的名字
-   守护进程具备以下特征：
    -   生命周期很长，守护进程会在系统启动的时候被创建并一直运行直至系统被关闭
    -   它在后台运行并且不拥有控制终端。没有控制终端确保了内核永远不会为守护进程自动生成任何控制信号以及终端相关的信号（如 SIGINT、SIGQUIT）
-   Linux的大多数服务器就是用守护进程实现的。比如，Internet 服务器 inetd，Web服务器 httpd

#### 守护进程创建步骤

-   执行一个fork()，之后父进程退出，子进程继续执行
-   子进程调用setsid() 开启一个新会话
-   清除进程的umask以确保当守护进程创建文件和目录时拥有所需的权限
-   修改进程的当前工作目录，通常会改为根目录（ / ）
-   关闭守护进程从其父进程继承而来的所有打开着的文件描述符
-   在关闭了文件描述符0、1、2之后，守护进程通常会打开/dev/null 并使用dup2() 使所有这些描述符指向这个设备
-   核心业务逻辑

## 显示进程

-   ps aux / ajx

    查看进程

    a :  显示终端上的所有进程, 包括其他用户进程

    u : 显示进程的详细信息

    x : 显示没有控制终端的进程

    j : 列出与作业控制相关的信息

-   top

    实时显示进程动态

    -d 设置刷新间隔时间

-   kill 

    杀死进程

    kill [-signal] pid	杀死进程

    kill -l 列出所有信号

    kill -9 / -SIGKILL  进程ID	强制杀死进程

    killall name 根据进程名杀死进程

## 显示进程

-   pid_t getpid(void)

    获取当前进程ID

-   pid_t getppid(void)

    获取当前进程的父进程ID

## 进程创建

-   pid_t fork(void)

    创建当前子进程

    返回值: 成功:子进程中返回0,父进程返回子进程ID;失败返回-1

    失败原因:当前系统进程数达到上限(errno:EAGAIN);系统内存不足(errno:ENOMEM)
    
    通过fork()复制当前进程创建出的子进程除了pid不同外,(虚拟地址的)用户区数据和内核区都一样,具体来说(fork是写时拷贝):一开始fork完,用户区资源是共享的(共享同一个空间地址),内核区还是要独立的,但是部分内核区数据一样,只要是只读状态那么用户区资源都是共享的,只有在写入修改的情况下才会开始复制数据(分配新的内存)
    
-   父子进程的区别

    1.fork()的函数返回值不同

    ​	父进程中:>0 返回的子进程ID

    ​	子进程中:=0

    2.pcb中的一些数据不同

    ​	当前进程ID pid

    ​	当前进程的父进程ID pid

    ​	信号集

-   父子进程的共同点

    某些状态下:子进程刚被创建出来,还没执行任何写数据的操作

    ​	用户区数据一样

    ​	文件描述符表一样

    父子进程对变量的共享情况:

    ​	刚开始时,是一样的,共享的.如果修改了数据,不共享了

    ​	(读时共享(没有进行任何写的操作),写时拷贝)

## 进程退出

-   void exit(int status)

    #include<stdlib.h>

    status: 退出时的状态.父进程回收子进程时可以获取

-   void _exit(int status)

    #include<unistd.h>

![image-20220303200239408](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203032002638.png)

## 孤儿进程

父进程结束运行,但子进程还在运行(未运行结束),这样的子进程就叫孤儿进程

每当出现一个孤儿进程时,内核就把孤儿进程的父进程设置为init, 而init进程会循环地wait()它的已经退出的子进程.当孤儿进程结束其生命周期时,init进程会回收.

孤儿进程没什么危害

## 僵尸进程

每个进程结束之后,都会释放自己地址空间中的用户区数据,内核区的PCB没有办法自己释放,需要父进程释放.

进程终止时,父进程尚未回收,子进程残留资源(PCB)存放于内核中,变成僵尸进程.

僵尸进程无法被kill -9杀死

-   危害:

    如果父进程不调用wait()或waitpid()的话,那么残留的信息将不会释放,其进程号会一直被占用,但系统的进程号是有限的,如果产生大量的僵尸进程,将因为没有可用的进程号而导致系统不能产生新的进程
    

## 进程回收

在每个进程退出的时候，内核释放该进程所有的资源、包括打开的文件、占用的内存等。但是仍然为其保留一定的信息，这些信息主要指进程控制块PCB的信息（进程号、退出状态、运行时间等）。

父进程可以调用wait()或waitpid()得到它的退出状态同时彻底清除掉这个进程。

一次wait()或waitpid()调用只能清理一个子进程，清理多个子进程应使用循环。

### wait()和waitpid()异同

-   相同

    函数的功能相同

-   差异

    wait()会阻塞；waitpid()可以设置不阻塞，还可以指定等待哪个子进程结束	

### wait

pid_t wait(int *wstatus)

-   功能

    等待任意一个子进程结束，如果任意一个子进程结束了，次函数会回收子进程的资源

-   参数

    wstatus：进程退出时的状态信息，传入的是一个int型的地址，传出参数

-   返回值

    成功：返回被回收的子进程的id

    失败：-1 （所有子进程都结束了，或者调用函数失败）

-   过程：

    调用wait函数的进程会被挂起（阻塞），知道它的一个子进程退出或者收到一个不能被忽视的信号时才被唤醒

    如果没有子进程了，函数立刻返回，返回-1；如果子进程都结束了，函数也会立刻返回-1

### waitpid

pid_t waitpid(pid_t pid, int *wstatus, int options)

-   功能

    回收指定进程号的子进程，可以设置是否阻塞

-   参数

    pid：

    ​	pid > 0：某个子进程的pid

    ​	pid = 0：回收当成进程组的所有子进程

    ​	pid  = -1：回收所有的子进程，相当于wait()

    ​	pid < -1：某个进程组的组id的绝对值，回收指定进程组中的子进程

    options：设置阻塞或非阻塞

    ​	0：阻塞

    ​	WNOHANG：非阻塞（即：没有子进程会立即返回）

-   返回值

    \> 0：返回被回收的子进程id

    = 0：options = WNOHANG，表示还有子进程或者还有子进程没有退出	

    = -1：错误，或者没有子进程

### 退出信息相关宏函数

-   WIFEXITED(status) 

    非0，进程正常退出

-   WEXITSTATUS(status)

    如果宏为真，获取进程退出的状态（exit的参数）

-   WIFSIGNALED(status)

    非0，进程异常终止

-   WTERMSIG(status)

    如果宏为真，获取使进程终止的信号编号

-   WIFSTOPPED(status)

    非0，进程处于暂停状态

-   WSTOPSIG(status)

    如果宏为真，获取使进程暂停的信号编号

-   WIFCONTINUED(status)

    非0，进程暂停后已经继续运行

## 终端

-   在unix 系统中，用户通过终端登录系统后得到一个shell 进程，这个终端成为shell 进程的控制终端，进程中，控制终端是保存在PCB 中的信息，而fork() 会复制PCB中的信息，因此由shell 进程启动的其他进程的控制终端也是这个终端
-   默认情况下（没有重定向），每个进程的标准输入、标准输出和标准错误输出都指向终端，进程从标准输入读也就是读用户的键盘输入，进程往标准输出或标准错误输出写也就是输出到显示器上
    -   在控制终端输入一些特殊的控制键可以给前台进程发信号，例如Ctrl + C 会产生SIGINT 信号， Ctrl + \ 会产生SIGQUIT信号

# 进程间通信（IPC）

## 概念

进程是一个独立的资源分配单元，不同进程（通常指用户进程）之间的资源是独立的，没有关联，不能在一个进程中直接访问另一个进程的资源。

但是，进程不是孤立的，不同的进程需要进行信息的交互和状态的传递等，因此需要进程间通信

## 目的

-   数据传输：一个进程需要将它的数据发送给另一个进程
-   通知时间：一个进程需要向另一个或一组进程发送消息，通知它（他们）发生了某种事情（如：进程终止时要通知父进程）
-   资源共享：多个进程之间共享同样的资源。为了做到这点，需要内核提供互斥和同步机制
-   进程控制：有些进程希望完全控制另一个进程的执行（比如debug [gdb]进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。

## 方式

![image-20220314001725009](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203140024844.png)

## 匿名管道(PIPE)

### 内容

UNIX系统IPC的最古老形式，所有的UNIX系统都支持这种通信方式

例：

统计一个目录中文件数目命令 ls | wc - l，（中间的‘|’为管道符） 为了执行该命令，shell创建了两个进程来分别执行ls和wc。

![image-20220314082224893](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203140822953.png)

### 特点

-   管道其实时一个在内核内存中维护的缓冲器，这个缓冲器的存储能力有限，不同的操作系统大小不一定相同

-   管道拥有文件的特质：读操作、写操作，匿名管道没有文件实体，有名管道有文件实体，但不存储数据。可以按照操作文件的方式对管道进行操作

-   一个管道是一个字节流，使用管道时不存在消息或者消息边界的概念，从管道读取数据的进程可以读取任意大小的数据块，而不管写入进程写入管道的数据块的大小是多少

-   通过管道传递的数据是顺序的，从管道中读取出来的字节的顺序和它们被写入管道的顺序是完全一样的

-   在管道中的数据的传递方向是单向的，一端用于写入，一端用于读取，管道是半双工的。

-   从管道读数据是一次性操作，数据一旦被读走，它就从管道中被抛弃，释放空间以便写更多数据，在管道中无法使用lseek()来随机的访问数据

-   匿名管道只能在具有公共祖先的进程（父进程与子进程，或者两个兄弟进程，具有亲缘关系）之间使用

    ![image-20220314083951833](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203140839883.png)

### 管道的数据结构

是个循环队列，有两个指针：一个是读指针，一个是写指针

### 匿名管道的使用

#### 创建匿名管道

-   int pipe(int pipefd[2])

    -   功能：创建一个匿名管道，用来进程间通信

    -   参数：int pipefd[2] 这个数组是一个传出参数

        ​	pipefd[0]	对应的是管道的读端

        ​	pipefd[1]	对应的是管道的写端

    -   返回值：

        ​	成功：0

        ​	失败：-1

    -   管道默认是阻塞的：如果管道中没有数据，read阻塞，如果管道满了，write阻塞

    -   注意：匿名管道只能用于具有关系的进程之间的通信（父子进程，兄弟进程）

#### 查看管道缓冲大小命令

-   ulimit -a

#### 查看管道缓冲大小函数

-   long fpathconf(int fd, int name)

### 匿名管道通信情况

![image-20220314094253863](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203140942924.png)

如图第1、2种情况都会造成自己读自己写进管道的信息，所以一般都是要用第3种（通过close(对应pipefd端口)实现）

### 匿名管道的读写特点

-   所有的指向管道写端的文件描述符都关闭了（管道写端引用计数为0），有进程从管道的读端读取数据，那么管道种剩余的数据被读取后，再次read会返回0，就像读到文件末尾一样

-   如果有指向管道写端的文件描述符没有关闭（管道的写端引用计数>0），而持有管道写端的进程也没有往管道中写数据，这时候有进程从管道中读取数据，那么管道中剩余的数据被读取后，再次read会阻塞，直到管道中有数据可以读了才读取数据并返回

-   如果所有指向管道读端的文件描述符都关闭了（管道的读端引用计数为0），这个时候有进程向管道中写数据，那么该进程会收到一个信号SIGPIPE（管道破裂），通常会导致进程异常终止

-   如果有指向管道读端的文件描述符没有关闭（管道的读端引用计数>0），而持有管道读端的进程也没有从管道中读数据，这时候有进程向管道中写数据，那么在管道被写满的时候，再次write会阻塞，直到管道中有空位置才能再次写入数据并返回

-   总结：

    ​	读管道：

    ​		管道中有数据，read返回实际读到的字节数

    ​		管道中无数据：

    ​			写端被全部关闭，read返回0

    ​			写端没有完全关闭，read阻塞等待

    ​	写管道：

    ​		管道读端全部被关闭，进程异常终止（进程收到SIGPIPE信号）

    ​		管道读端没有全部关闭：

    ​			管道已满，write阻塞

    ​			管道没有满，write将数据写入，并返回实际写入的字节数

### 设置非阻塞

通过fcntl将fd修改成非阻塞的

## 有名管道（FIFO）

### 内容

-   匿名管道，由于没有名字，只能用于亲缘关系的进程间通信。为了克服该缺点，提出了有名管道，也叫命名管道、FIFO文件。
-   有名管道不同于匿名管道之处在于它提供了一个路径名与之关联，以FIFO的文件形式存在于文件系统中，并且其打开方式与打开一个普通文件是一样的，这样即使与FIFO的创建进程不存在亲缘关系，只要可以访问该路径，就能够彼此通过FIFO相互通信，因此，通过FIFO不想关的进程也能交换数据
-   一旦打开了FIFO，就能在它上面使用与操作匿名管道和其他文件的系统调用一样的I/O系统调用。和管道一样，FIFO也有一个输入端和读取段，并且从管道中读取数据的顺序与写入的顺序是一样的。

### FIFO与PIPE的异同

FIFO和PIPE有一些特点是相同的，不同的地方在于：

1. FIFO在文件系统中作为一个特殊文件存在，但FIFO中的内容却存放在内存中
2. 当使用FIFO的进程退出后，FIFO文件将继续保存在文件系统中以便以后使用
3. FIFO有名字，不相关的进程可以通过打开有名管道进行通信

### 有名管道的使用

####  创建有名管道

-   通过命令创建有名管道

    mkfifo 名字

-   通过函数创建有名管道

    int mkfifo(const char *pathname, mode_t mode)

    -   参数：

        ​	pathname：管道名称的路径

        ​	mode：文件的权限，和open的mode是一样的，是个八进制的数

    -   返回值：

        ​	成功：0

        ​	失败：-1，并设置错误号

#### 使用

-   一旦使用mkfifo创建了一个FIFO，就可以使用open打开它，常见的I/O函数都可以用。
-   FIFO严格遵循先进先出，对管道及FIFO的读总是从开始处返回数据，对他们的写则把数据添加到末尾。不支持lseek()等文件定位操作

#### 注意事项

-   一个为只读而打开一个管道的进程会阻塞，直到另一个进程为只写打开管道

-   一个为只写而打开一个管道的进程会阻塞，直到另一个进程为只读打开管道

-   总结：

    ​	读管道：

    ​		管道中有数据，read返回实际读到的字节数

    ​		管道中无数据：

    ​			管道写端被全部关闭，read返回0

    ​			写端没有全部被关闭，read阻塞等待

    ​	写管道：

    ​		管道读端被全部关闭，进行异常终止（收到一个SIGPIPE信号）

    ​		管道读端没有全部被关闭：

    ​			管道已经满了，write会阻塞

    ​			管道没有满，write将数据写入，并返回实际写入的字节数

## 内存映射

### 内容

内存映射是将磁盘文件的数据映射到内存（动态库加载的区域），用户通过修改内存就能修改磁盘文件

![image-20220314153744018](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203141537077.png)

### 相关系统调用

-   void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset)

    -   功能：将一个文件或者设备的数据映射到内存中

    -   参数：

        ​	void *addr：NULL，由内核指定

        ​	length：要映射的数据的长度，非0，（建议使用文件的长度）

        ​		获取文件的长度：stat lseek

        ​	prot：对申请的内存映射区的操作权限

        ​		PROT_EXEC：可执行权限

        ​		PROT_READ：读权限（要操作映射区，必须要有读权限）

        ​		PROT_WRITE：写权限	（一般还要有读权限）

        ​		PROT_NONE：没有权限

        ​	flags：

        ​		MAP_SHARED：映射区的数据会自动和磁盘文件进行同步，进程间通信必须要设置该选项

        ​		MAP_PRIVATE：不同步，内存映射区的数据改变了，不会修改原来的文件，会重新创建一个新的文件（copy on write)

        ​	fd：需要映射的那个文件的文件描述符

        ​		通过open得到，open的是一个磁盘文件

        ​		（注意：文件大小不能为0， open指定的权限不能和prot参数有冲突）

        ​	offset：要映射数据在文件中的偏移量，一般不用（必须指定的是4k的整数倍，0表示不偏移）

    -   返回值：

        ​	成功：返回创建的内存的首地址

        ​	失败：返回一个宏MAP_FAILED（(void *) -1)

-   int munmap(void *addr, size_t length)

    -   功能：释放内存映射

    -   参数：

        addr：要释放的内存的首地址

        length：要释放的内存的大小，要和mmap函数中的length参数的值一样

### 注意事项

-   可以对mmap的返回值（ptr）进行++操作，但是不能对++操作后的ptr进行munmap（会错误，要对原ptr地址进行munmap）

-   如果open权限与mmap里的prot权限冲突（比如：open是O_RDONLY，mmap的prot是PROT_READ | PROT_WRITE），则会发生错误，返回一个宏MAP_FAILED

-   如果文件偏移量不是4k的整数会返回MAP_FAILED

-   mmap调用失败的情况

    ​	第二个参数：length = 0

    ​	第三个参数：prot

    ​			只指定了写权限

    ​			与open的权限冲突

-   可以在open的时候通过O_CREAT一个新文件来创建映射区，但是大小不能为0，否则错误（可以通过lseek()或者truncate()对文件进行拓展）

-   mmap后关闭open的文件描述符，对mmap映射没有影响，因为mmap的文件描述符相当于对fd进行了拷贝

-   对ptr越界操作，因为越界操作操作的是非法内存，会导致段错误

### 匿名映射

不需要文件实体的内存映射，只能在父子进程间通信，通过修改mmap中的参数来实现匿名映射

## 信号

### 概念

-   信号是Linux进程间通信的最古老的方式之一，是事件发生时对进程的通知机制，有时也称之为软件中断，它是在软件层次上对中断机制的一种模拟，是一种异步通信的方式。信号可以导致一个正在运行的进程被另一个正在运行的异步进程中断，转而处理某一个突发事件。
-   发往进程的诸多信号，通常都是源于内核。引发内核为进程产生信号的各类事件：
    -   对于前台进程，用户可以通过输入特殊的终端字符来给它发送信号。比如输入Ctrl + C通常会给进程发送一个中断信号
    -   硬件发生异常，即硬件检测到一个错误条件并通知内核，随即再由内核发送相应信号给相关进程。比如执行一条异常的机器语言指令：被0除，或者引用了无法访问的内存区域
    -   系统状态变化。比如alarm定时器到期将硬气SIGALRM信号，进程执行的CPU事件超限，或者该进程的某个子进程退出
    -   运行kill命令或者调用kill函数

### 主要目的

-   让进程知道已经发生了一个特定的事情
-   强迫进程执行它自己代码中的信号处理程序

### 信号的特点

-   简单
-   不能携带大量信息
-   满足某个特定条件才发送
-   优先级比较高

### 查看系统定义的信号

-   kill -l

    前31个信号为常规信号，其余为实时信号

-   信号的5种默认处理动作
    -   Term 终止进程
    -   Ign 当前进程忽略掉这个信号
    -   Core 终止进程，并生成一个Core文件
    -   Stop 暂停当前进程
    -   Cont 继续执行当前被暂停的进程
-   信号的3种状态：产生、未决、递达
-   SIGKILL 和 SIGSTOP信号不能被捕捉、阻塞或者忽略，只能执行默认动作

### 信号集

-   许多信号相关的系统调用都需要能表示一组不同的信号，多个信号可使用一个称之为信号集的数据结构来表示，其系统数据类型为sigset_t
-   在PCB种有两个非常重要的信号集。一个称之为“阻塞信号集”，另一个称之为“未决信号集“。这两个信号集都是内核使用位图机制（二进制）来实现的。但操作系统不允许我们直接对这两个信号集进行位操作。而需自定义另外一个集合，借助信号集操作函数来对PCB中这两个信号集进行修改（事实上只能修改阻塞信号集，未决信号集只读）
-   信号的”未决“是一种状态，指的是从信号的产生到信号被处理前的这一段时间
-   信号的”阻塞“是一个开关动作，指的是阻止信号被处理，但不是阻止信号产生
-   信号的阻塞就是让系统暂时保留信号留待以后发送。由于另外有办法让系统忽略信号，所以一般情况下信号的阻塞只是暂时的，只是为了防止信号打断敏感的操作

-   例子：
    1.   用户通过键盘Ctrl + C，产生2号信号SIGINT(信号被创建)
    2.   信号产生但没有被处理（未决）
         -   在内核中将所有的没有被处理的信号存储在一个集合中（未决信号集）
         -   SIGINT信号状态被存储在第二个标志位上
             -   这个标志位的值为0，说明信号不是未决状态
             -   这个标志位的值为1，说明信号处于未决状态
    3.   这个未决状态的信号，需要被处理，处理之前需要和另一个信号集（阻塞信号集）进行比较
         -   阻塞信号集默认不阻塞任何的信号
         -   如果想要阻塞某些信号需要用户调用系统的API
    4.   在处理的时候和阻塞信号集中的标志位继续宁查询，看是否对该信号设置了阻塞
         -   如果没有阻塞，该信号就被处理
         -   如果阻塞了，这个信号就继续处于未决状态，直到阻塞解除，这个信号就被处理

![image-20220315081023950](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203150811487.png)

### 信号相关函数

-   int kill(pid_t pid, int sig)

    -   功能：给某个进程pid，发送某个信号sig

    -   参数：

        ​	pid：需要发送给的进程的id

        ​		> 0：将信号发送给指定的进程

        ​		= 0：将信号发送给当前的进程组

        ​		= -1：将信号发送给每一个有权限接受这个信号的进程

        ​		<-1：这个pid=某个进程组的ID取反

        ​	sig：需要发送的信号的编号或者是宏值（0表示不发送任何信号）

-   int raise(int sig)

    -   功能：给当前进程发送信号

    -   返回值：

        ​	成功：0

        ​	失败：非0

-   void abort(void)

    -   功能：发送SIGABRT信号给当前的进程，杀死当前进程

-   unsigned int alarm(unsigned int seconds)

    -   特点：

        -   非阻塞
        -   与进程的状态无关（自然定时法）。无论进程处于什么状态，alarm都会计时

    -   功能：设置定时器（闹钟）。

        ​	函数调用，开始倒计时，当倒计时为0的时候，函数会给当前进程发送一个信号：SIGALARM

    -   参数：

        ​	seconds：倒计时的时长，单位：秒。如果参数为0，定时器无效（不进行倒计时，不发信号）。取消一个定时器也是通过：alarm(0)

    -   返回值：

        ​	之前没有定时器，返回0	

        ​	之前有定时器，返回之前的定时器剩余的时间

    -   SIGALARM：默认终止当前的进程，每一个进程都有且只有唯一的一个定时器

-   int setitimer(int which, const struct itimerval *new_val, struct itimerval *old_value)

    -   特点：非阻塞的

    -   功能：设置定时器（闹钟）。可以替代alarm函数。精度微秒us，可以实现周期性定时。

    -   参数：

        -   which：定时器以什么时间计时
            -   ITIMER_REAL：真实时间，时间到达，发送SIGALARM	常用
            -   ITIMER_VIRTUAL：用户时间，时间到达，发送SIGVTALRM
            -   ITIMER_PROF：以该进程在用户态和内核态下所消耗的时间来计算，时间到达，发送SIGPROF
        -   new_value：设置定时器的属性
        -   old_value：记录上一次定时的时间参数，一般不适用，指定NULL

    -   返回值：

        成功：0

        失败 ：-1	并设置错误号
    
    ### 信号集相关函数
    
-   int sigemptyset(sigset_t *set)

    -   功能：清空信号集中的数据，将信号集中的所有二点标志位置置为0
    -   参数：set，传出参数，需要操作的信号集
    -   返回值：成功返回0；失败返回-1

-   int sigfillset(sigset_t *set)

    -   功能：将信号集中的所有的标志位置为1
    -   参数：set，传出参数，需要操作的信号集
    -   返回值：成功返回0；失败返回-1

-   int sigaddset(sigset_t *set, int signum)

    -   功能：设置信号集中的某一个信号对应的标志位为1，表示阻塞这个信号
    -   参数：
        -   set：传出参数，需要操作的信号集
        -   signum：需要设置阻塞的那个信号
    -   返回值：成功返回0；失败返回-1

-   int sigdelset(sigset_t *set, int signum)

    -   功能：设置信号集中的某一个信号对应的标志位为0，表示不阻塞这个信号
    -   参数：
        -   set：传出参数，需要操作的信号集
        -   signum：需要设置不阻塞的那个信号
    -   返回值：成功返回0；失败返回-1

-   int sigismember(const sigset_t *set, int signum)

    -   功能：判断某个信号是否阻塞
    -   参数：
        -   set：需要操作的信号集
        -   signum：需要判断的那个信号
    -   返回值：
        -   1：signum被阻塞
        -   0：signum不阻塞
        -   -1：失败

（以上信号集相关的函数都是对自定义的信号集进行操作）

-   int sigprocmast(int how, const sigset_t *set, sigset_t *oldset)

    -   功能：将自定义信号集中的数据设置到内核中（设置阻塞，解除阻塞，替换）

    -   参数：

        -   how：如何对内核阻塞信号集进行处理 （假设内核中默认的阻塞信号集是mask，自定义信号集为set）

            ​	SIG_BLOCK：将用户设置的阻塞信号集添加到内核中，内核中原来的数据不变

            ​		（mask | set）

            ​	SIG_UNBLOCK：根据用户设置的数据，对内核中的数据进行解除阻塞

            ​		（mask &= ~set）

            ​	SIG_SETMASK：覆盖内核原来的值
            
        -   set：已经初始化好的用户自定义的信号集
        
        -   oldset：传出参数，保存设置之前内核中的阻塞信号集中的状态，可以是NULL
        
    -   返回值：

        -   成功：0
        -   失败：-1，设置错误号：EFAULT、EINVAL

-   int sigpending(sigset_t *set)

    -   功能：获得内核中的未决信号集
    -   参数：set，传出参数，保存的是内核中的未决信号集中的信息

### 信号捕捉函数

-   sighandler_t signal(int signum, sighandler_t handler)

    typedef void (*sighandler_t)(int) 函数指针

    -   功能：设置某个信号的捕捉行为

    -   参数：

        -   signum：要捕捉的信号

        -   handler：捕捉到信号要如何处理

            ​	SIG_IGN：忽略信号

            ​	SIG_DFL：使用信号默认的行为

            ​	回调函数：这个函数是内核调用，程序员只负责写，捕捉到信号后如何去处理信号

    -   返回值：

        ​	成功：返回上一次注册的信号处理函数的地址。第一次调用返回NULL

        ​	失败：返回SIG_ERR，设置错误号

    -   SIGKILL、SIGSTOP不能被捕捉，不能被忽略

-   int sigaction(int signum, const struct sigaction *act, struct sigaction *oldact)、

    ```C++
    struct sigaction{
        //	函数指针，指向的函数就是信号捕捉到之后的处理函数
        void (*sa_handler)(int);
        //	不常用
        void (*sa_sigaction)(int, siginfo_t *, void *);
        //	临时阻塞信号集，在信号捕捉函数执行过程中，临时阻塞某些信号
        sigset_t sa_mast;
        //	使用哪一个信号处理对捕捉到的信号进行处理
        	//	这个值可以是0, 表示使用sa_handler
        	//	也可以是SA_SIGINFO表示使用sa_sigaction
        int sa_flags;
        //	被废弃了
        void (*sa_restorer)(void);
    }
    ```

    -   功能：检查或者改变信号的处理。信号捕捉
    -   参数：
        -   signum：需要捕捉的信号的编号或者宏值（信号的名称）
        -   act：捕捉到信号之后的处理动作
        -   oldact：上一次对信号捕捉相关的设置，一般不适用，传递NULL
    -   返回值：成功0；失败-1

### 内核实现信号捕捉的过程

![image-20220315093706878](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203150947924.png)

### SIGCHLD信号

-   产生条件
    -   子进程终止时
    -   子进程接收到SIGSTOP信号停止时
    -   子进程处于停止态，接受到SIGCONT后唤醒时
    -   以上3种条件都会给父进程发送SIGCHLD信号，父进程默认忽略该信号
    
-   作用：可以通过父进程对其捕获来实现回收僵尸进程，解决僵尸进程问题

    （注意：在捕捉SIGCHLD之前有可能子进程已经结束，所以要先设置阻塞信号集阻塞SIGCHLD）

## 共享内存

### 内容

-   共享内存允许两个或者多个进程共享物理内存的同一块区域（通常被称为段）。由于一个共享内存段是成为一个进程用户空间的一部分，因此这种IPC机制无需内核接入。所有需要做的就是让一个进程将数据复制进共享内存中，并且这部分数据会对其他所有共享同一个段的进程可用。
-   与管道等要求发送进程将数据从用户空间的缓冲区复制进内核内存和接受进程将数据从内核内存复制进用户空间的缓冲区的做法相比，这种IPC技术的速度更快

### 共享内存使用步骤

-   调用shmget() 创建一个新共享内存段或取得一个既有共享内存段的标识符（即由其他进程创建的共享内存段）。这个调用将返回后续调用中需要用到的共享内存标识符。
-   使用shmat()来附上共享内存段，即：使该段成为调用进程的虚拟内存（动态库那部分）的一部分
-   此刻在程序中可以像对待其他可用内存那样对待这个共享内存段。为引用这块共享内存，程序需要使用由shmat()调用返回的addr值，它是一个指向进程的虚拟地址空间中该共享内存段的起点的指针。
-   调用shmdt()来分离共享内存段。在这个调用之后，进程就无法再引用这块共享内存了。这一步是可选的，并且再进程终止时会自动完成这一步。
-   调用shmctl()来删除共享内存段。只有当当前所有附加内存段的进程都与之分离之后内存段才会销毁。只有一个进程需要执行这一步。

### 共享内存操作函数

-   int shmget(key_t key, size_t size, int shmflg)

    -   功能：创建一个新的共享内存段，或者获取一个既有的共享内存段的标识

        ​	新创建的内存段中的数据都会被初始化为0

    -   参数：

        -   key：key_t类型时一个整型，通过这个找到或者创建一个共享内存

            ​	一般使用16进制表示，非0值

        -   size：共享内存的大小（分页的整数倍）

        -   shmflg：属性

            ​	访问权限

            ​	附加属性：创建 / 判断共享内存是不是存在 / 获取

            ​		创建：IPC_CREAT

            ​		判断共享内存是否存在：IPC_EXCL，需要和IPC_CREAT一起使用（IPC_CREAT | IPC_EXCL | 0664)

        -   返回值：

            -   失败：-1并设置错误号
            -   成功：>0返回共享内存的引用ID，后面操作共享内存都是通过这个值

-   void *shmat(int shmid, const void *shmaddr, int shmflg)

    -   功能：和当前的进程进行关联

    -   参数：

        -   shimid：共享内存的标识（ID），由shmget返回值获得

        -   shmaddr：申请的共享内存的起始地址，指定NULL，内核指定

        -   shmflg：对共享内存的操作

            ​	 读权限：SHM_RDONLY，必须要有读权限

            ​	读写：0

        -   返回值：

            -   成功：返回共享内存的首（起始）地址
            -   失败：(void *) -1

-   int shmdt(const void *shmaddr)

    -   功能：解除当前进程和共享内存的关联
    -   参数：
        -   shmaddr：共享内存的首地址
    -   返回值：成功0；失败-1

-   int shmctl(int shmid, int cmd, struct shmid_ds *buf)

    -   功能：对共享内存进行操作（主要是删除操作），共享内存要删除才会消失，创建共享内存的进程被销毁了对共享内存没有影响

    -   参数：

        -   shmid：共享内存的ID

        -   cmd：要做的操作

            ​	IPC_STAT：获取共享内存的当前状态

            ​	IPC_SET：设置共享内存的状态

            ​	IPC_RMID：标记共享内存被销毁

        -   buf：需要设置或者获取的共享内存的属性信息

            ​	IPC_STAT： buf存取数据

            ​	IPC_SET：buf中需要初始化数据，设置到内核中

            ​	IPC_RMID：没有用，NULL

-   key_t ftok(const char *pathname, int proj_id)

    -   功能：根据指定的路径，和int值，生成一个共享内存的key

    -   参数：

        -   pathname：指定一个存在的路径

        -   proj_id：int类型的值，但是这系统调用只会使用其中的1个字节

            ​	范围：0-255，一般指定一个字符 ‘a’

### 共享内存操作命令

-   ipcs命令
    -   ipcs -a	//	打印当前系统中所有的进程间通信方式的信息
    -   ipcs -m   //    打印出使用共享内存进行进程间通信的信息
    -   ipcs -q    //    打印出使用消息队列进行进程间通信的信息
    -   ipcs -s    //    打印出使用信号进行进程间通信的信息
-   ipcrm命令
    -   ipcrm -M shmkey	//	移除用shmkey创建的共享内存段
    -   ipcrm -m shmid	//	移除用shmid表示的共享内存段
    -   ipcrm -Q msgkey	//	溢出用msqkey创建的消息队列
    -   ipcrm -q msqid	//	移除用msqid标识的消息队列
    -   ipcrm -S semkey	//	移除用semkey创建的信号
    -   ipcrm -s semid	//	移除用semid标识的信号

### 共享内存相关总结

-   操作系统如何知道一块共享内存被多少个进程关联

    -   共享内存维护了一个结构体struct shmid_ds 这个结构体有一个成员 shm_nattch
    -   shm_nattach记录了关联的进程个数

-   可不可以对共享内存进行多次删除 shmctl

    -   可以

    -   因为shmctl 标记删除共享内存，而不是直接删除

    -   当和共享内存关联的进程数为0的时候，就真正被删除了

    -   当共享内存的key为0的时候，表示共享内存被标记删除了

        ​	如果一个进程和共享内存取消关联，那么这个进程就不能继续操作这个共享内存，也不能进行关联

    -   共享内存和映射的区别

        1.   共享内存可以直接创建，内存映射需要好磁盘文件（匿名映射除外）

        2.   共享内存效果更高

        3.   内存

             1.   所有的进程操作的是同一块共享内存
             2.   内存映射，每个进程在自己的虚拟地址空间中有一个独立的内存

        4.   数据安全

             1.   进程突然退出
                  -   共享内存还存在
                  -   内存映射区小时
             2.   运行进程的电脑司机，宕机了
                  -   数据存在在共享内存中，没有了
                  -   内存映射区的数据，由于磁盘文件中的数据还在，所以内存映射区的数据还存在

        5.   生命周期

             -   内存映射区：进程退出，内存映射区销毁

             -   共享内存：进程退出，共享内存还在，标记删除（所有的关联的进程数为0），或者关机

                 ​	如果一个进程退出，会自动和共享内存进行取消关联 	

# 线程

## 概况

-   与进程类似，线程是允许应用程序并发执行多个任务的一种机制。一个进程可以包括多个线程。同一个程序中的所有线程均会独立执行相同程序，且共享同一份全局内存区域，其中包括初始化数据段、未初始化数据段，以及堆内存段。（传统意义上的UNIX进程只是多线程程序的一个特例，该进程只包含一个线程）
-   进程是CPU分配资源的最小单位，线程是操作系统调度执行的最小单位
-   线程是轻量级的进程(LWP)，在Linux环境下线程的本质仍是进程
-   查看指定进程的LWP号： ps -Lf pid

## 线程和进程的区别

-   进程间的信息难以共享。由于除去只读代码段外，父子进程并未共享内存，因此必须采用一些进程间通信方式，在进程间进行信息交换
-   调用fork() 来创建进程的代价相对较高，即便利用写时复制计数，仍然需要复制诸如内存页表和文件描述符表之类的多种进程属性，这意味着fork() 调用在时间上的开销仍然不菲
-   线程之间能够方便、快速地共享信息。只需将数据复制到共享（全局或堆）变量中即可
-   创建线程比创建进程通常要快10倍甚至更多。线程间时共享虚拟地址空间的，无需采用写时复制来复制内存，也无需复制页表

## 线程之间共享和非共享的资源

-   共享资源
    -   进程ID和父进程ID
    -   进程组ID和会话ID
    -   用户ID和用户组ID
    -   文件描述符表
    -   信号处置
    -   文件系统的相关信息：文件权限掩码（umask）、当前工作目录
    -   虚拟地址空间（除栈、.text)
-   非共享资源
    -   线程ID
    -   信号掩码
    -   线程特有数据
    -   error变量
    -   实时调度策略和优先级
    -   栈、本地变量和函数的特用链接信息

![image-20220316114809189](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203161148647.png)

## 线程操作

一般情况下，main函数所在的线程称为主线程（main线程），其余创建的线程称之为子线程

-   int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(\*start_routine)(void *), void *arg)

    -   功能：创建一个子线程

    -   参数：

        -   thread：传出参数，线程创建成功后，子线程的线程ID被写到该变量中
        -   attr：设置线程的属性，一般使用默认值，NULL
        -   start_routine：函数指针，这个函数是子线程需要处理的逻辑代码，是个回调函数
        -   arg：给第3个参数使用，传参

    -   返回值：

        -   成功：0

        -   失败：返回错误号，这个错误号和之前的errno不太一样

            ​	获取错误号的信息：char *strerror(int errnum)

-   void pthread_exit(void *retval)

    不会影响其他线程

    -   功能：终止一个线程，在哪个线程中调用，就表示终止哪一个线程
    -   参数：
        -   retval：需要传递一个指针，作为一个返回值，可以在pthread_join() 中获取到

-   pthread_t pthread_self(void)

    -   功能：获取当前的线程的线程ID

-   int pthread_equal(pthread_t t1, pthread_t t2)

    -   功能：比较两个线程ID是否相等

        不同的操作系统，pthread_t类型的实现不一样，有的是无符号的长整型，有的是使用结构体去实现的

-   int pthread_join(pthread_t thread, void **retval)

    -   功能：和一个已经终止的线程进行连接

        ​	回收子线程的资源

        ​	这个函数是阻塞函数，调用一次只能回收一个子线程

        ​	一般在主线程中使用

    -   参数：

        -   thread：需要回收的子线程的ID
        -   retval：接受子线程退出时的返回值

    -   返回值：

        -   0：成功
        -   非0：失败，返回的错误号

-   int pthread_detach(pthread_t thread)

    -   功能：分离一个线程。被分离的线程在终止的时候，会自动释放资源返回给系统。
        1.   不能多次分离，会产生不可预料的行为
        2.   不能去连接一个已经分离的线程，会报错
    -   参数：需要分离的线程的ID
    -   返回值：
        -   成功：0
        -   失败：返回错误号

-   int pthread_cancel(pthread_t thread)

    -   功能：取消线程（让线程终止）

        ​	取消某个线程，可以终止某个线程的运行

        ​	但是并不是立马终止，而是当子线程执行到一个取消点，线程才会终止

        ​	取消点：系统规定好的一些系统调用，粗略的理解为从用户区到内核区的切换，这个位置称之为取消点

## 线程属性

-   int pthread_attr_init(pthread_attr_t *attr)
    -   功能：初始化线程初始化变量
-   int pthread_attr_destroy(pthread_attr_t *attr)
    -   功能：释放线程属性的资源
-   int pthread_attr_getdetachstate(const pthread_attr_t *attr, int *detachstate)
    -   功能：获取线程分离的状态属性
-   int pthread_attr_setdetachstate(const pthread_attr_t *attr, int detachstate)
    -   功能：设置线程分离的状态属性

## 线程同步

-   线程的主要优势在于，能够通过全局变量来共享信息。不过，这种便捷的共享是有代价的：必须确保多个线程不会同时修改同一变量，或者某一线程不会读取正在由其他线程修改的变量
-   临界区是指访问某一共享资源的代码片段，并且这段代码的执行应为原子操作，也就是同时访问同一共享资源的其他线程不应中断该片段的执行
-   线程同步：即当由一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线程完成操作，其他线程才能对该内存地址进行操作，而其他线程则处于等待状态

## 互斥量（mutex）

-   为避免线程更新共享变量时出现问题，可以使用互斥量（mutex）来确保同时仅有一个线程可以访问某项共享资源。可以使用互斥量来保证对任意共享资源的原子访问
-   互斥量有两种状态：已锁定（locked）和未锁定（unlocked）。任何时候，至多只有一个线程可以锁定该互斥量。试图对已经锁定的某一互斥量再次加锁，将可能阻塞线程或者报错失败，具体取决于加锁时使用的方法
-   一旦线程锁定互斥量，随即成为该互斥量的所有者，只有所有者才能给互斥量解锁。一般情况下，对每一共享资源（可能由多个相关变量组成）会使用不同的互斥量，每一线程在访问同一资源时将采用如下协定
    1.   针对共享资源锁定互斥量
    2.   访问共享资源
    3.   对互斥量解锁

## 互斥量相关操作函数

互斥量的类型	pthread_mutex_t

-   int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr)

    -   功能：初始化互斥量

    -   参数：

        -   mutex：需要初始化的互斥量变量
        -   attr：互斥量相关的属性，NULL

        restrict：C语言的修饰符，被修饰的指针，不能由另外的一个指针进行操作

-   int pthread_mutex_destroy(pthread_mutex_t *mutex)

    -   功能：释放互斥量的资源

-   int pthread_mutex_lock(pthread_mutex_t *mutex)

    -   功能：加锁，阻塞的，如果有一个线程加锁了，那么其他的线程只能阻塞等待

-   int pthread_mutex_trylock(pthread_mutex_t *mutex)

    -   功能：尝试加锁，如果加锁失败，不会阻塞，直接返回

-   int pthread_mutex_unlock(pthread_mutex_t *mutex)

    -   功能：解锁

## 死锁

-   有时，一个线程需要同时访问两个或更多不同的共享资源，而每个资源又都有不同的互斥量管理。当超过一个线程加锁同一组互斥量时，就有可能发生死锁。
-   两个或两个以上的进程在执行过程中，因争夺共享资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁
-   常见的死锁：
    -   忘记释放锁
    -   重复加锁
    -   多线程多锁，抢占锁资源

## 读写锁

-   当有一个线程已经持有互斥锁时，互斥锁将所有试图进入临界区的线程都阻塞住。但是考虑一种情况，当前持有互斥锁的线程只是要读访问共享资源，而同时有其他几个线程也想读取这个共享资源，但是由于互斥锁的排他性，所有其他线程都无法获取锁，也就无法读访问共享资源了，但是实际上多个线程同时读访问共享资源并不会导致问题
-   在对数据的读写操作中，更多的是读操作，写操作较少，例如对数据库数据的读写应用。为了满足当前能够允许多个读出，但是只允许一个写入的需求，线程提供了读写锁来实现
-   读写锁的特点
    -   如果有其他线程读数据，则允许其他线程执行读操作，但不允许写操作
    -   如果有其他线程写数据，则其他线程都不允许读、写操作
    -   写是独占的，写的优先级高

## 读写锁相关操作函数

读写锁 pthread_rwlock_t

-   int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr)
    -   功能：初始化读写锁
-   int pthread_rwlock_destroy(pthread_rwlock_t *rwlock)
    -   功能：释放读写锁的资源
-   int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock)
    -   功能：读加锁
-   int pthread_rwlock_tryrdlock(pthread_rwlock_t *rwlock)
    -   功能：尝试读加锁
-   int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock)
    -   功能：写加锁
-   int pthread_rwlock_trywrlock(pthread_rwlock_t *rwlock)
    -   功能：尝试写加锁
-   int pthread_rwlock_unlock(pthread_rwlock_t *rwlock)
    -   功能：解锁

## 生产者消费者模型

![image-20220316215716908](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203162157967.png)

## 条件变量

-   作用：主要是阻塞线程，不能保证线程安全

条件变量的类型 pthread_cond_t

-   int pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr)

-   int pthread_cond_destroy(pthread_cond_t *cond)

-   int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex)

    -   功能：等待，阻塞函数，调用该函数，线程会阻塞

        ​	当这个函数调用阻塞的时候，会对互斥锁进行解锁

        ​	当不阻塞的时候，继续向下执行，会对互斥锁进行重新上锁

-   int pthread_cond_timedwait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex, const struct timespec *restrict abstime)

    -   功能：等待多长时间，阻塞函数，调用该函数，线程会阻塞，直到指定时间结束

        ​	当这个函数调用阻塞的时候，会对互斥锁进行解锁

        ​	当不阻塞的时候，继续向下执行，会对互斥锁进行重新上锁

-   int pthread_cond_signal(pthread_cond_t *cond)

    -   功能：唤醒一个或多个等待的线程

-   int pthread_cond_broadcast(pthread_cond_t *cond)

    -   功能：唤醒所有的等待的线程

## 信号量（信号灯）

-   作用主要是阻塞线程，不能保证线程安全

    信号量的类型 sem_t

-   int sem_init(sem_t *sem, int pshared, unsigned int value)

    -   功能：初始化信号量
    -   参数：
        -   sem：信号量变量的地址
        -   pshared：0用在线程间，非0用在进程间
        -   value：信号量中的值

-   int sem_destroy(sem_t *sem)

    -   功能：释放资源

-   int sem_wait(sem_t *sem)

    -   功能：对信号量加锁，调用一次对信号量的值-1，如果值为0，就阻塞

-   int sem_trywait(sem_t *sem)

-   int sem_timedwait(sem_t *sem, const struct timespec *abs_timeout)

-   int sem_post(sem_t *sem)

    -   功能：对信号量解锁，调用一次对信号量的值+1，当sem值>0就会唤醒其他调用sem_wait被阻塞的线程

-   int sem_getvalue(sem_t *sem, int *sval)

# 网络结构模式

## C / S 结构

### 简介

>    服务器 - 客户机。C / S 结构通常采取两层结构服务器负责数据的管理，客户机负责完成与用户的交互任务。客户机是因特网上访问别人信息的机器，服务器则是提供信息供人访问的计算机
>
>   客户机通过局域网与服务器相连，接受用户的请求，并通过网络向服务器提出请求，对数据库进行操作。服务器接受客户机的请求，将数据提交给客户机，客户机将数据进行计算并将结果呈现给用户。服务器还要提供完善安全保护及对数据完整性的处理等操作，并允许多个客户机同时访问服务器，这就对服务器的硬件处理数据能力提出了很高的要求
>
>   在C / S结构中，应用程序分为两部分：服务器部分和客户机部分。服务器部分是多个用户共享的信息与功能，执行后台服务，如控制共享数据库的操作等；客户机部分为用户所专有，负责执行前台功能，在出错提示、在线帮助等方面都有强大的功能，并且可以在子进程间自由切换

### 优点

1.   能充分发挥客户端PC 的处理能力，很多工作可以在客户端处理后再提交给服务器，所以C / S结构客户端响应速度快
2.   操作界面漂亮、形式多样，可以充分满足客户自身的个性化要求
3.   C / S 结构的管理信息系统具有较强的事务处理能力，能实现复杂的业务流程
4.   安全性较高，C / S 一般面对相对固定的用户群，程序更加注重流程他可以对权限进行多层次校验，提供了更安全的存取模式，对信息安全的控制能力很强，一般高度机密的信息系统采用C / S结构适宜

### 缺点

1.   客户端需要安装专用的客户端软件。首先涉及到安装的工作量，其次任何一台电脑出问题，如病毒、硬件损坏，都需要进行安装或维护。系统软件升级时，每一台客户机需要重新安装，其维护和升级成本非常高
2.   对客户端的操作系统一般也会有限制，不能够跨平台

## B / S结构

### 简介

>浏览器 - 服务器模式。是WEB兴起后的一种网络结构模式，WEB浏览器是客户端最主要的应用软件。这种模式统一了客户端，将系统功能实现的核心部分集中到服务器上，简化了系统的开发、维护和使用。客户机上只要安装了一个浏览器，服务器安装SQL Server、Oracle、MySQL等数据库。浏览器通过Web Server同数据库进行数据交互

### 优点

​	B / S架构最大的优点是总体拥有成本低、维护方便、分布性强、开发简单，可以不用安装任何专门的软件就能实现在任何地方进行操作，客户端零维护，系统的拓展非常容易，只要有一台能上网的电脑就能使用

### 缺点

1.   通信开销大、系统和数据的安全性较难保障
2.   个性特点明显降低，无法实现具有个性化的功能要求
3.   协议一般是固定的：http / https
4.   客户端服务端的交互式请求-响应模式，通常动态刷新页面，响应速度明显降低

## 网络模型

### OSI 7层模型

### TCP / IP 四层模型

#### 简介

>现在因特网使用的主流协议族是TCP / IP 协议族，它是一个分层、多层协议的通信体系。TCP / IP协议族是一个四层协议系统，自底而上分别是数据链路层、网络层、传输层和应用层。每一层完成不同的功能，且通过若干协议来实现，上层协议使用下层协议提供的服务

![image-20220317010956607](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203170109685.png)

>TCP / IP协议在一定程度上参考了OSI 的体系结构。OSI模型共有7层，这显然是有些复杂的，所以在TCP / IP 协议中，它们被简化为了4个层次
>
>1.   应用层、表示层、会话层三个层次提供的服务相差不是很大，所以在TCP / IP 协议中，它们被合并为了应用层
>2.   由于传输层和网络层在网络协议中的地位十分重要，所以在TCP / IP协议中它们被作为独立的两个层次
>3.   因为数据链路层和物理层的内容相差不多，所以在TCP / IP协议中它们被归并在网络接口层
>
>只有4层体系结构的TCP / IP协议，与有7层体系结构的OSI 相比要简单了不少，也正式这样， TCP / IP 协议在实际的应用中效率更高，成本更低

![image-20220317011729807](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203170117867.png)

## 协议

### 常见协议

-   应用层常见协议： 
    -   FTP协议（文件传输协议）
    -   HTTP协议（超文本传输协议）
    -   NFS（网络文件系统）
-   传输层常见协议：
    -   TCP协议（传输控制协议）
    -   UDP协议（用户数据报协议）
-   网络常见协议：
    -   IP协议（因特网互联协议）
    -   ICMP协议（因特网控制报文协议）
    -   IGMP协议（因特网组管理协议）
-   网络接口层常见协议：
    -   ARP协议（地址解析协议）
    -   RARP协议（反向地址解析协议）

## 网络通信的过程

### 封装

>   上层协议是通过封装来实现使用下层协议提供的服务的。应用程序数据在发送到物理网络上之前，将沿着协议栈从上往下依次传递。每层协议都将在上层数据的基础上加伤自己的头部信息（有时还包括尾部信息），以实现该层的功能，这个过程称为封装

![image-20220317013345144](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203170133227.png)

### 分用

>   当帧到达目的主机时，将沿着协议栈自底向上依次传递。各层协议依次处理帧中本层负责的头部数据，以获取所需的信息，并最终将处理后的帧交给目标应用程序。这个过程称为分用。分用是依靠头部信息中的类型字段实现的。

![image-20220317013811540](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203170138611.png)

![image-20220317013854021](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203170138101.png)

## 字节序(大端小端问题)

### 简介
>现代CPU的累加器一次都能装载(至少)4字节(对于32位机),即一个整数.那么这4字节在内存中排列的顺序将影响它被累加器装载成整数的值,这就是字节序问题.在克重计算机可惜结构中,对于字节/字等的存储机制有所不同,因而引发了计算机通信领域中一个很重要的问题,即通信双方交流的信息单元(比特/字节/字/双字等)应该以什么样的顺序进行传哦是那个.如果不达成一致的规则,通信双方将无法进行正常的编码/译码从而导致通信失败
>
>**字节序,顾名思义字节的顺序,就是大于一个字节类型的数据在内存中存放顺序**
>**字节序分为大端字节序(Big-Endian)和小端字节序(Little-Endian).大端字节序是指一个整数的最高位字节(23~31 bit)存储在内存的低地址处,低位字节(0~7 bit)存储在内存的高地址处;小端字节序则是指整数的高位字节存储在内存的高地址处,而低位字节则存储在内存的低地址处**
### 字节序转换函数
>当格式化的数据在两台使用不同字节序的主机之间直接传递时,接收端必然错误的解释之.解决问题的方法时:发送端总是把要发送的数据转换成大端字节序数据后再发送,而接收端知道对方传输过来的数据总是采用大端字节序,所以接收端可以根据自身采用的字节序决定是否对接收到的数据进行转换(小端机转换,大端机不转换)
>**网络字节顺序**时TCP / IP 中规定好的一种数据表示格式,它与具体的CPU类型/操作系统等无关,从而可以保证数据在不同主机之间传输时能够被正确解释,网络字节顺序采用大端排序方式
>BSD Socket提供了封装好的转换接口,方便程序员使用.包括从主机字节序到网络字节序的转换函数:htons/htonl;从网络字节序到主机字节序的转换函数:ntohs/ntohl
>h - host 主机,主机字节序
>to - 转换成什么
>n - network 网络字节序
>s - unsigned short
>l - unsigned long
>
- uint16_t htons(uint16_t hostshort)
    	- 转换端口,主机字节序到网络字节序
- uint16_t ntohs(uint16_t netshort)
    	- 转换端口,网络字节序到主机字节序
- uint32_t htonl(uint32_t hostlong)
    	- 转换IP,主机字节序到网络字节序
- uint32_t ntohl(uint32_t netlong)
    	- 转换IP,网络字节序到主机字节序

## Socket（套接字）

>所谓socket（套接字），就是对网络中不同主机上的应用进程之间进行双向通信的端点的抽象。一个套接字就是网络上进程通信的一段，提供了应用层进程利用网络协议交换数据的机制。从所处的地位来讲，套接字上联应用进程，下联网络协议栈，是应用程序通过网络协议进行通信的接口，是应用程序与网络协议根进行交互的接口
>
>socket可以看成是两个网络应用程序进行通信时，各个通信连接中的端点，这是一个逻辑上的概念。它时网络环境中进程间通信的API，也是可以被命名和寻址的通信端点，使用中的每一个套接字都有其类型和一个与之相连进程。通信时其中一个网络应用程序将要传输的一段信息写入它所在主机的socket中，该socket通过与网络接口卡（NIC）相连的传输介质将这段信息传送到另外一台主机的socket中，使对方能够接收到这段信息。socket是由IP 地址和端口结合的，提供向应用层进程传送数据包的机制
>
>socket本身有“插座”的意思，在Linux 环境下，用于表示进程间网络通信的特殊文件类型。本质为内核借助缓冲区形成的伪文件。既然是文件，那么理所当然的，我们可以使用文件描述符引用套接字。与管道类似的，Linux系统将其封装称文件的目的是为了统一接口，使得读写套接字和读写文件的操作一致。区别是管道主要应用于本地进程通信，而套接字多应用于网络进程间数据的传输。

-   套接字通信分两部分：
    -   服务端：被动接受连接，一般不会主动发起连接
    -   客户端：主动向服务器发起连接
-   socket是一套通信的接口，Linux和Windows都有，但是有一些细微的差别
## socket地址
### 通用socket地址
**socket网络变成接口中表示socket地址的时结构体sockaddr**

```C++
	struct sockaddr {
		sa_family_t sa_family;
		char 	sa_data[14];
	};
	typedef unsigned short int sa_family_t;
```

**sa_family成员是地址族类型(sa_family_t)的变量.**地址族类型通常与协议族类型对应.常见的协议族(domain)和对应的地址族:
- PF_UNIX	AF_UNIX	UNIX本地域协议族
- PF_INET	AF_INET	TCP/IPv4协议族
- PF_INET6	AF_INET6	TCP/IPv6协议族

宏PF_*和AF_*具有完全相同的值,可以混用
**sa_data成员用于存放socket地址值.**但是不同的协议族的地址值具有不同的含义和长度:
- PF_UNIX	文件的路径名,长度可达108字节
- PF_INET	16bit端口号和32bit IPv4地址,共6字节
- PF_INET6	16bit端口号,32bit流标识,128bit IPv6地址,32bit范围ID,共26字节

由于旧的sa_data无法存储IPv6,所以推出了新的通用socket地址结构体,**这个结构体不仅提供了足够大的空间用于存放地址值,而且是内存对齐的**
```C++
	struct sockaddr_storage{
		sa_family_t sa_family;
		unsigned long int __ss_align;
		char __ss_padding[128 - sizeof(__ss_align)];
	};
	typedef unsigned short int sa_family_t;
```
### 专用socket地址
> 很多网络编程函数诞生早于IPv4协议,那时候都使用的是struct sockaddr结构体,为了向前兼容,现在sockaddr 退化成了(void *)的作用,传递一个地址给函数,至于这个函数是sockaddr_in还是sockaddr_in6,由地址族确定,然后函数内部再强制类型转化为所需的地址类型

![image-20220317102847485](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203171028908.png)

```C++
struct sockaddr_in{
    sa_family_t sin_family;	/* 协议*/
    in_port_t sin_port;	/* 端口 */
    struct in_addr sin_addr;	/* 网络IP地址 */
    unsigned char sin_zero[sizeof(struct sockaddr) - __SOCKADDR_COMMON_SIZE - sizeof(in_port_t) - sizeof(struct in_addr)];
};

struct in_addr {
    in_addr_t s_addr;
};

struct sockaddr_in6 {
    sa_family_t sin6_family;
    in_port_t sin6_port;	/* 端口 */
    uint32_t sin6_flowinfo;		/* IPv6流信息 */
    struct in6_addr sin6_addr; 	/* IPv6地址 */
    uint32_t sin6_scope_id;		/* IPv6 scope-id */
};

typedef unsigned short uint16_t;
typedef unsigned int uint32_t;
typedef uint16_t in_port_t;
typedef uint32_t in_addr_t;
#define __SOCKADDR_COMMON_SIZE (sizeof(unsigned short int))
```

**所有专用socket地址(以及sockaddr storage)类型的变量在实际使用时都需要转化为通用socket地址类型sockaddr(强制转换即可),因为所有socket编程接口使用的地址参数类型都是sockaddr**

## IP地址转换(字符串ip-整数)

>   通常,人们习惯用可读性号的字符串来表示IP地址,比如用点分十进制字符串表示IPv4地址,以及用十六进制字符串表示IPv6地址.但编程中我们需要先把它们把转化成整数(二进制数)方能使用.而记录日志时则相反,我们要把整数表示的IP地址转化成可读的字符串.

-   int inet_pton(int af, const char *src, void *dst)
    -   功能:将点分十进制的IP字符串转化成网络字节序的整数
    -   参数:
        -   af:地址族
            -   AF_INET: IPv4
            -   AF_INET6: IPv6
        -   src:需要转换的点分十进制字符串的IP字符串
        -   dst:传出参数,转换后的结果
-   const char *inet_ntop(int af, const void *src, char *dst, socklen_t size)
    -   功能:将网络字节序的整数转化成点分十进制的IP字符串
    -   参数:
        -   af:地址族
            -   AF_INET: IPv4
            -   AF_INET6: IPv6
        -   src: 要转换的ip的整数的地址
        -   dst: 传出参数
        -    size: 第三个参数的大小(数组的大小)
    -   返回值:返回转化后的数据的地址(字符串),和dst时一样的

p: 点分十进制的IP字符串; n:表示network,网络字节序的整数

## TCP通信流程

![image-20220318161642594](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203181616715.png)

### 服务端（被动接受连接的角色）

1.   创建一个用于监听的套接字
     -   监听：监听有客户端的连接
     -   套接字：这个套接字其实就是一个文件描述符
2.   将这个监听文件描述符和本地的IP 和端口绑定（IP和端口就是服务器的地址信息）
     -   客户端连接服务器的时候使用的就是这个IP 和端口
3.   设置监听，监听的fd 开始工作
4.   阻塞等待，当有客户端发起连接，解除阻塞，接受客户端的连接，会得到一个和客户端通信的套接字（fd）**这个fd和上面监听的fd不一样，每accpet一个都会返回一个新的fd用于处理这个新的连接，上面监听的fd只是用于监听**
5.   通信
     -   接受数据
     -   发送数据
6.   通信结束，断开连接

### 客户端

1.   创建一个用于通信的套接字（fd）
2.   连接服务器，需要指定连接的服务器的IP和端口
3.   连接成功了，客户端可以直接和服务器通信
     -   接受数据
     -   发送数据
4.   通信结束，断开连接

## 套接字（socket）函数

-   int socket(int domain, int type, int protocol)

    -   功能：创建一个套接字
    -   参数：
        -   domain：协议族
            -   AF_INET：ipv4
            -   AF_INET6：ipv6
            -   AF_UNIX，AF_LOCAL：本地套接字通信（进程间通信）
        -   type：通信过程中使用的协议类型
            -   SOCK_STREAM：流式协议
            -   SOCK_DGRAM：报式协议
        -   protocol：具体的一个协议。一般写0
            -   SOCK_STREAM：流式协议默认使用TCP
            -   SOCK_DGRAM：报式协议默认使用UDP
        -   返回值
            -   成功：返回文件描述符，操作的就是内核缓冲区
            -   失败：-1

-   int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen)

    -   功能：绑定，将fd和本地的IP+端口进行绑定
    -   参数：
        -   sockfd：通过socket函数得到的文件描述符
        -   addr：需要绑定的socket地址，这个地址封装了ip和端口号的信息
        -   addrlen：第二个参数结构体占的内存大小
    -   返回值：
        -   成功：0
        -   失败：-1

-   int listen(int sockfd, int backlog)

    -   功能：监听这个socket上的连接

    -   参数：

        -   sockfd：通过socket()函数得到的文件描述符

        -   backlog：未连接的和已经连接的和的最大值

            ​	每个监听套接字接口都维护两个队列：

            ​		未完成连接队列：服务器处于listen状态时收到客户端syn报文，放入该队列

            ​		已完成连接队列：三次握手完成后转到已完成连接队列尾部

    -   返回值：

        -   成功：0
        -   失败：-1

-   int accept(int sockfd, struct sockaddr *addr, socklen_t  *addrlen)

    -   功能：接受客户端连接，默认是一个阻塞的函数，阻塞等待客户端连接
    -   参数：
        -   sockfd：用于监听的文件描述符
        -   addr：传出参数，记录了连接成功后客户端的地址信息（ip，port）
        -   addrlen：指定第二个参数的对应的内存大小
    -   返回值：
        -   成功：用于通信的文件描述符
        -   失败：-1

-   int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen)

    -   功能：客户端连接服务器
    -   参数：
        -   sockfd：用于通信的文件描述符
        -   addr：客户端要连接的服务器的地址信息
        -   addrlen：第二个参数的内存大小
    -   返回值：
        -   成功：0
        -   失败：-1

-   ssize_t write(int fd, const void *buf, size_t count)

    -   功能：写数据

-   ssize_t read(int fd, const void *buf, size_t count)

    -   功能：读数据

## TCP 3次握手

![image-20220405004624344](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204050046434.png)

-   第一次握手
    1.   客户端将SYN标志位置尾1
    2.   生成一个随机的32位的序号，这个序号后面可以携带数据（数据大小）
    
-   半连接队列(syn queue)未满

    服务器将该连接的状态变为SYN_RCVD, 服务器把连接信息放到半连接队列(syn queue)里面服务器将该连接的状态变为SYN_RCVD, 服务器把连接信息放到半连接队列(syn queue)里面。

-   半连接队列(syn queue)已满

    服务器**不会**将该连接的状态变为SYN_RCVD，且将该连接丢弃(SYN flood攻击就是利用这个原理

-   第二次握手：
    1.   服务端接受客户端的连接：ACK=1

    1.   服务端会回发一个确认序号：ack=客户端的序号+数据长度+SYN/FIN（按一个字节算）
    2.   服务端会向客户端发起连接请求：SYN=1
    3.   服务端会生成一个随机序号：seq = k

-   第三次握手：
    1.   客户端应答服务器的连接请求：ACK=1
    2.   客户端回复收到了服务端的数据：ack=服务端的序号+数据长度+SYN/FIN（按一个字节算）
    
-   全连接队列(accept queue)未满
    服务器收到客户端发来的ACK, 服务端该连接的状态从SYN_RCVD变为ESTABLISHED,
    然后服务器将该连接从半连接队列(syn queue)里面移除，且将该连接的信息放到全连接队列(accept queue)里面。

-   全连接队列(accept queue)已满
    服务器收到客户端发来的ACK, 不会将该连接的状态从SYN_RCVD变为ESTABLISHED。
    当然全连接队列(accept queue)已满时，则根据 tcp_abort_on_overflow 的值来执行相应动作
    /proc/sys/net/ipv4/tcp_abort_on_overflow 查看参数值

## SYN_FLOOD（DDOS）

>Syn-Flood攻击是当前网络上最为常见的DDoS攻击，也是最为经典的拒绝服务攻击，它利用了TCP协议实现上的一个缺陷，**通过向网络服务所在端口发送大量的伪造源地址的攻击报文，就可能造成目标服务器中的半开连接队列被占满，从而阻止其他合法用户进行访问。**
>
>这种攻击早在1996年就被发现，但至今仍然显示出强大的生命力。很多操作系统，甚至防火墙、路由器都无法有效地防御这种攻击，而且由于它可以方便地伪造源地址，追查起来非常困难。**它的数据包特征通常是，源发送了大量的SYN包，并且缺少三次握手的最后一步握手ACK回复。**

### 攻击原理

攻击者首先伪造地址对服务器发起SYN请求（我可以建立连接吗？），服务器就会回应一个ACK+SYN（可以+请确认）。而真实的IP会认为，我没有发送请求，不作回应。服务器没有收到回应，会重试3-5次并且等待一个SYN Time（一般30秒-2分钟）后，丢弃这个连接。

如果攻击者大量发送这种伪造源地址的SYN请求，服务器端将会消耗非常多的资源来处理这种半连接，保存遍历会消耗非常多的CPU时间和内存，何况还要不断对这个列表中的IP进行SYN+ACK的重试。TCP是可靠协议，这时就会重传报文，默认重试次数为5次，重试的间隔时间从1s开始每次都番倍，分别为1s + 2s + 4s + 8s +16s = 31s,第5次发出后还要等32s才知道第5次也超时了，所以一共是31 + 32 = 63s。

也就是说一共假的syn报文，会占用TCP准备队列63s之久，而半连接队列默认为1024（系统默认不同）。也就是说在没有任何防护的情况下，每秒发送200个伪造syn包，就足够撑爆半连接队列，从而使真正的连接无法建立，无法响应正常请求。 最后的结果是服务器无暇理睬正常的连接请求—拒绝服务。

### 防御手段

-   cookie源认证

    原理是syn报文首先由DDOS防护系统来响应syn_ack。带上特定的sequence number （记为cookie）。真实的客户端会返回一个ack 并且Acknowledgment number 为cookie+1。 而伪造的客户端，将不会作出响应。这样我们就可以知道那些IP对应的客户端是真实的，将真实客户端IP加入白名单。下次访问直接通过，而其他伪造的syn报文就被拦截。

![image-20220405003501565](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204050035685.png)

-   reset认证

    Reset认证利用的是TCP协议的可靠性，也是首先由DDOS防护系统来响应syn。防护设备收到syn后响应syn_ack,将Acknowledgement number (确认号)设为特定值（记为cookie）。当真实客户端收到这个报文时，发现确认号不正确，将发送reset报文，并且sequence number 为cookie + 1。 而伪造的源，将不会有任何回应。这样我们就可以将真实的客户端IP加入白名单。 

![image-20220405003602471](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204050036539.png)

-   TCP首包丢弃

    该算法利用了TCP/IP协议的重传特性，来自某个源IP的第一个syn包到达时被直接丢弃并记录状态(五元组)，在该源IP的第2个syn包到达时进行验证，然后放行。

    当防御设备接到一个IP地址的SYN报文后:

    1.   接受到syn报文      -> 简单比对该IP是否存在于白名单中:   存在则转发到后端，否则进行第2步
    2.   不存在于白名单中 -> 检查是否是该IP在一定时间段内的首次SYN报文： 不是则进行第3步，是则进行第5步
    3.   不是首次SYN报文 -> 检查是否重传报文： 是重传则转发并加入白名单，不是则丢弃并加入黑名单
    4.   是首次SYN报文    ->  丢弃并等待一段时间以试图接受该IP的SYN重传报文，等待超时则判定为攻击报文加入黑名单。

    **缺点：首包丢弃方案对用户体验会略有影响，因为丢弃首包重传会增大业务的响应时间，有鉴于此发展出了一种更优的TCP Proxy方案。**

### TCP Proxy方案

所有的SYN数据报文由清洗设备接受，按照SYN Cookie方案处理。和设备成功建立了TCP三次握手的IP地址被判定为合法用户加入白名单，由设备伪装真实客户端IP地址再与真实服务器完成三次握手，随后转发数据。而指定时间内没有和设备完成三次握手的IP地址，被判定为恶意IP地址屏蔽一定时间。除了SYN Cookie结合TCP Proxy外，清洗设备还具备多种畸形TCP标志位数据包探测的能力，通过对SYN报文返回非预期应答测试客户端反应的方式来鉴别正常访问和恶意行为。

清洗设备的硬件具有特殊的网络处理器芯片和特别优化的操作系统、TCP/IP协议栈，可以处理非常巨大的流量和SYN队列。

## TCP滑动窗口

>滑动窗口是一种流量控制技术。早期的网络通信种，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。滑动窗口协议是用来改善吞吐量的一种技术，即：容许发送方在接受任何应答之前传送附加的包。接收方告诉发送方在某一时刻能送多少包（称窗口尺寸）
>
>TCP种采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接受数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为0时，，发送方一般不能再发送数据报。
>
>滑动窗口是TCP中实现诸如ACK确认、流量控制、拥塞控制的承载结构

### 特点

-   窗口理解为缓冲区的大小
-   滑动窗口的大小会随着发送数据和接受数据而变化
-   通信的双方都有发送缓冲区和接受数据的缓冲区
    -   服务器：
        -   发送缓冲区（发送缓冲区的窗口）
        -   接受缓冲区（接受缓冲区的窗口）
    -   客户端：
        -   发送缓冲区（发送缓冲区的窗口）
        -   接受缓冲区（接受缓冲区的窗口）

![image-20220319145726626](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203191457693.png)

-   发送方的缓冲区：
    -   白色格子：空闲的空间
    -   灰色格子：数据已经被发送出去了，但是还没有被接受
    -   紫色格子：还没有发送出去的数据
-   接收方的缓冲区：
    -   白色格子：空间的空间
    -   紫色格子：已经接受到的数据

### 例子

![image-20220319152400716](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203191524811.png)

>mss：Maximum Segment Size（一条数据的最大的数据量）
>
>win：滑动窗口
>
>1.   客户端向服务器发起连接，客户端的滑动窗口是4096，一次发送的最大数据量是1460
>2.   服务器接收连接情况，告诉客户端服务器的窗口大小是6144，一次发送的最大数据量是1024
>3.   第三次握手
>4.   4~9次，客户端连续给服务端发送了6k的数据，每次发送1k
>5.   第10次，服务端告诉客户端：发送的6k数据已经接收到，存储在缓冲区中，缓冲区数据已经处理了2k，窗口大小是2k
>6.   第11次，服务端告诉客户端：发送的6k数据已经接收到，存储在缓冲区中，缓冲区数据已经处理了4k，窗口大小是4k
>7.   第12次，客户端给服务端发送了1k的数据
>8.   第13次，客户端主动请求和服务端断开连接，并且给服务端发送了1k的数据
>9.   第14次，服务端回复ACK 8194，表示：同意断开连接的请求，告诉客户端已经接收到方才发的2k数据，滑动窗口2k 
>10.   第15、16次，通知客户端滑动窗口的大小
>11.   第17次，第三次挥手，服务端给客户端发送FIN，请求断开连接
>12.   第18次，第四次挥手，客户端同意了服务端的断开请求

## 拥塞控制

>   -   拥塞现象：
>
>       是指到达通信子网中某一部分的分组数量过多，使得该部分网络来不及处理，以致引起这部分乃至整个网络性能下降的现象，严重时甚至会导致网络通信业务陷入停顿，即出现死锁现象。
>
>   -   拥塞控制：
>
>       防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提：网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的所有因素。
>
>   -   TCP拥塞控制的难点：
>
>       判断什么时候需要减缓和如何减缓TCP传输、什么时候恢复其原有速度。
>       典型的TCP判断拥塞：用丢包作为判断拥塞发生与否的指标，衡量是否实施相应的措施。
>
>   -   **四种拥塞控制方法：**
>
>       1.   满开始（slow-start）
>       2.   拥塞避免（congestion avoidance）
>       3.   快重传（fast retransmit）
>       4.   快恢复（fast recovery）

### 慢开始和拥塞避免

>   发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。
>   发送端实际可用的窗口：接收端通知窗口（流量控制中的发送窗口）和拥塞窗口中的较小者。
>   发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。

-   慢开始

    **慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小**

    当然收到单个确认但此确认多个数据报的时候就加相应的数值。所以一次传输轮次之后拥塞窗口就加倍。这就是乘法增长，和后面的拥塞避免算法的加法增长比较。

    ![image-20220406141921742](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204061419855.png)

    为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh状态变量。ssthresh的用法如下：
    1). 当cwnd<ssthresh时，使用慢开始算法。
    2). 当cwnd>ssthresh时，改用拥塞避免算法。
    3). 当cwnd=ssthresh时，慢开始与拥塞避免算法任意。

-   拥塞避免

    RTT（Round-Trip Time） ：往返时间。是指一个报文段从发出去到收到此报文段的ACK所经历的时间。通常一个报文段的RTT与传播时延和发送时延两个因素相关。

    拥塞避免算法让拥塞窗口缓慢增长，**即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。**

    无论是在**慢开始阶段**还是在**拥塞避免阶段**，只要发送方判断网络出现拥塞（其根据就是没有收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限设置为出现拥塞时的发送窗口大小的一半。然后把拥塞窗口设置为1，执行慢开始算法。如下图：

    ![image-20220406142121511](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204061421565.png)

###  快重传和快恢复

-   快重传

    快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。

    ![image-20220406142257134](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204061422191.png)

-   快恢复

    快重传配合使用的还有快恢复算法，有以下两个要点:
    ①当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半。但是接下去并不执行慢开始算法。
    ②考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh的大小，然后执行拥塞避免算法。如下图：
    ![image-20220406143315577](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204061433639.png)

## TCP四次挥手

>   四次挥手发生在断开连接的时候，在程序中当调用了close()会使用TCP协议进行四次挥手
>
>   客户端和服务端都可以主动发起断开连接，谁先调用close()谁就是发起
>
>   因为在TCP连接的时候，采用三次握手简历的连接是双向的，在断开的连接也需要双向断开
>
>   -   **2MSL（Maximum Segment Lifetime）**
>
>       主动断开连接的一方，最后进入一个TIME_WAIT状态，这个状态会持续：2msl
>
>       -   msl：官方建议：2分钟，实际30s
>
>       当TCP连接主动关闭方接收到被动关闭方发送的FIN和最终的ACK后，连接的主动关闭方必须处于TIME_WAIT状态并且持续2MSL时间
>
>       这样就能够让TCP连接的主动关闭方在它发送的ACK丢失的情况下重新发送最终的ACK
>
>       主动关闭方重新发送的最终ACK并不是因为被动关闭方重传了ACK（它们并不消耗序列号，被动关闭方也不会重传），而是因为欸东关闭方重传了它的FIN。事实上，被动关闭方总是重传FIN直到它收到一个最终的ACK。
>
>   -   **半关闭**
>
>       当TCP链接中A向B发送FIN请求关闭，另一端B回应ACK之后（A端进入FIN_WAIT_2状态），并没有立即发送FIN给A，A方处于半连接状态（半开关），此时A可以接收B发送的数据，但是A已经不能再向B发送数据。

### API控制实现半连接状态

-   int shutdown(int sockfd, int how)

    -   参数：

        -   sockfd：需要关闭的socket的文件描述符
        -   how：允许为shutdown操作选择以下几种方式
            -   SHUT_RD(0)：关闭sockfd上的读功能，此选项将不允许sockfd进行读操作，该套接字不再接受数据，任何当前的套接字接受缓冲区的数据将被无声的丢弃掉
            -   SHUT_WR(1)：关闭sockfd的写功能，此选项将不允许sockfd进行写操作。进程不能在对此套接字发出写操作
            -   SHUT_RDWR(2)：关闭sockfd的读写操作。相当于调用shutdown两次：首先是以SHUT_RD，然后以SHUT_WR

        **注意：**

        1.   使用close终止一个连接，但它只是减少描述符的引用计数，并不直接关闭连接，只有当描述符的引用计数为0时才关闭连接。shutdown不考虑描述符的引用计数，直接关闭描述符。也可选择终止一个方向的连接，只中止读或只终止写
        2.   如果有多个进程共享一个套接字，close每被调用一次，计数减1，直到计数为0时，也就是所用进程都调用了close，套接字将被释放
        3.   在多进程中如果一个进程调用了shutdown(sfd, SHUT_RDWR)后，其他的进程将无法进行通信。但如果进程close(sfd)将不会影响到其他进程

![image-20220319153115691](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203191531747.png)

## TCP通信并发

>要实现TCP通信服务器处理并发的任务，使用多线程或者多进程来解决
>
>思路：
>
>1.   一个父进程，多个子进程
>2.   父进程负责等待并接受客户端的连接
>3.   子进程：完成通信，接受一个客户端连接，就创建一个子进程用于通信

## 端口复用

>端口复用常用用途：
>
>-   防止服务器重启时之前绑定的端口还未释放
>-   程序突然退出而系统没有释放端口

-   setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen)
    -   参数：
        -   sockfd：要操作的文件描述符
        -   level：级别 - SOL_SOCKET（端口复用的级别）
        -   optname：选项的名称
            -   SO_REUSERADDR
            -   SO_REUSERPORT
        -   optval：端口复用的值（整形）
            -   1：可以复用
            -   0：不可以复用
        -   optlen：optval参数的大小
    -   **注意：**端口复用设置的时机是在服务器绑定端口之前

## I/O多路复用（I/O多路转接）

>   I/O多路复用使得程序能够同时监听多个文件描述符，能够提升程序的性能，Linux下实现I/O多路复用的系统调用主要有select、poll和epoll

### BIO模型（阻塞等待）

-   好处：

    不占用CPU宝贵的时间片

-   缺点

    同一时刻只能处理一个操作，效率低

**用多线程、多进程改进**

-   缺点：

    1.   线程或进程会消耗资源
    2.   线程或进程调度会消耗CPU资源

-   **根本问题**

    blocking(阻塞)

### NIO模型（非阻塞，忙轮询）

-   优点：

    提高了程序的执行效率

-   缺点：

    需要占用更多的CPU和系统资源

每循环内O(n)系统调用

### 使用IO多路转接技术（select / poll / epoll）

>select / poll ：委托内核通知有多少个I / O
>
>epoll：委托内核通知有多少个I / O 和他们分别是哪几个

### select

>**主旨思想：**
>
>1.   首先要构造一个关于文件描述符的列表，将要监听的文件描述符添加到该列表中
>2.   调用一个系统函数，监听该列表中的文件描述符，直到这些描述符中的一个或者多个进行I / O操作时，该函数才返回
>     -   这个函数是阻塞的
>     -   该函数对文件描述符的检测的操作是由内核完成的
>3.   在返回时，它会告诉进程有多少（哪些）描述符要进行I / O 操作
>
>**缺点：**
>
>1.   每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
>2.   同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大
>3.   select支持的文件描述符数量很小，默认是1024
>4.   fds集合不能重用，每次都需要重置

-   int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout)

    -   参数：

        -   nfds： 委托内核检测的最大文件描述符的值+1（右开区间所以+1）

        -   readfds：要检测的文件描述符的读的集合，委托内核检测哪些文件描述符的读的属性

            ​	一般检测读操作

            ​	对应的对方发送过来的数据，因为读是被动的接受数据，检测的就是读缓冲区

            ​	是一个传入传出参数

        -   writefds：要检测的文件描述符的写的集合，委托内核检测哪些文件描述符的写的属性

            ​	委托内核检测写缓冲区是不是还可以写数据（不满的就可以写）

        -   exceptfds：检测发生异常的文件描述符的集合

        -   timeout：设置的超时时间

            ​	NULL：永久阻塞，直到检测到了文件描述符有变化

            ​	tv_sec = 0， tv_usec = 0，不阻塞

            ​	tv_sec > 0，tv_usec > 0，阻塞对应的时间

    -   返回值：

        -   -1：失败
        -   \> 0(n)：表示的集合中有n个文件描述符发生了变化

-   void FD_CLR(int fd, fd_set *set)

    -   功能：将参数文件描述符fd对应的标志位设置为0

-   int FD_ISSET(int fd, fd_set *set)

    -   功能：判断fd对应的标志位是0还是1
    -   返回值：fd对应的标志位的值；0，返回0；1，返回1

-   void FD_SET(int fd, fd_set *set)

    -   功能：将参数文件描述符fd对应的标志位，设置为1

-   void FD_ZERO(fd_set *set)

    -   功能：fd_set一共有1024 bit，全部初始化为0

### poll

-   **缺点：**

    1.   每次调用poll，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多的时候会很大
    2.   同时每次调用poll都需要在内核遍历传进来的所有的fd，这个开销在fd很多的时候也很大

-   int poll(struct pollfd *fds, nfds_t nfds, int timeout)

    ```C++
    struct pollfd {
        int fd;	//	委托内核检测的文件描述符
        short events; //	委托内核检测的文件描述符的什么事件
        short revents;	//	文件描述符实际发生的事情
    }
    ```

    

    -   参数：

        -   fds：这是一个需要检测的文件描述符的集合（数组）

        -   nfds：第一个参数数组中最后一个有效元素的下标+1

        -   timeout：阻塞时长

            ​	0：不阻塞

            ​	-1：阻塞，检测到需要检测的文件描述符有变化，解除阻塞

            ​	>0：阻塞的时长

    -   返回值：

        -   -1：失败
        -   \> 0(n)：成功，n表示检测到集合中有n个文件描述符发生变化

### epoll

-   int epoll_create(int size)

    -   功能：创建一个新的epoll实例。在内核中创建了一个数据，这个数据中有两个比较重要的数据，一个是需要检测的文件描述符的信息（红黑树），还有一个就是就绪列表，存放检测到数据发送改变的文件描述符信息（双向链表）
    -   参数：
        -   size：2.6之后没有意义，以前是hash。随便写一个非0的数
    -   返回值：
        -   -1：失败
        -   \> 0：文件描述符，操作epoll实例的

-   int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)

    -   功能：对epoll实例进行管理：添加文件描述符信息，删除信息，修改信息

    -   参数：

        -   epfd：epoll实例对应的文件描述符

        -   op：要进行什么操作

            ​	EPOLL_CTL_ADD：添加

            ​	EPOLL_CTL_MOD：修改

            ​	EPOLL_CTL_DEL：删除

        -   fd：要检测的文件描述符

        -   event：检测文件描述符什么事情

            ​	常见epoll检测事件： 

            ​		EPOLLIN

            ​		EPOLLOUT

            ​		EPOLLERR

            ​		EPOLLET（ET模式边沿触发）

-   int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout)

    -   功能：检测函数

    -   参数：

        -   epfd：epoll实例对应的文件描述符

        -   events：传出参数，保存了发送了变化的文件描述符的信息

        -   maxevents：第二个参数结构体数组的大小

        -   timeout：阻塞时间

            ​	0：不阻塞

            ​	-1：阻塞，直到检测到fd数据发生变化，解除阻塞

            ​	\>0：阻塞的时长（毫秒）

    -   返回值：

        -   成功，返回发送变化的文件描述符的个数 \> 0
        -   失败：-1

### epoll的两种工作模式：

-   LT模式(水平触发)

    >   LT是缺省（默认）的工作方式，并且同时支持block和no-block socket。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。

    假设委托内核检测读事件 -> 检测fd的读缓冲区

    ​	读缓冲区有数据 -> epoll检测到了会给用户通知

      		1. 用户不读数据，数据一直在缓冲区，epoll会一直通知
      		2. 用户只读了一部分数据，epoll会通知
      		3. 缓冲区的数据读完了，不通知

-   ET模式（边沿触发）

    >   ET是高速工作方式，支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了。但是请注意，如果一直不对这个fd作IO操作（从而导致它再次变成未就绪），内核不会发送更多的通知（only once）
    >
    >   ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读 / 阻塞写操作把处理多个文件描述符的任务饿死

    假设委托内核检测读事件 -> 检测fd的读缓冲区

    ​	读缓冲区有数据 -> epoll检测到了会给用户通知

    	1. 用户不读数据，数据一直在缓冲区中，epoll下次检测的时候就不通知了
    	2. 用户只读了一部分数据，epoll不通知
    	3. 缓冲区的数据读完了，不通知

## UDP

![image-20220323143016481](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203231431631.png)

-   ssize_t sento(int sockfd, const void *buf, size_t len, int flags, const struct sockaddr *dest_addr, socklen_t addrlen)
    -   参数：
        -   sockfd：通信的fd
        -   buf：要发送的数据
        -   len：发送数据的长度
        -   flags：一般用0
        -   dest_addr：通信的另外一端的地址信息
        -   addrlen：地址的内存大小
-   ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen)
    -   参数：
        -   sockfd：通信的fd
        -   buf：接受数据的数组
        -   len：数组的大小
        -   flags：一般为0
        -   src_addr：用来保存另一端的地址信息，不需要可以为NULL
        -   addrlen：地址的内存大小

## 广播

>   向子网中多台计算机发送消息，并且子网中所有的计算机都可以接受到发送方发送的消息，每个广播消息都包含一个特殊的IP地址，这个IP中子网内主机标志部分的二进制全部为1
>
>   1.   只能在局域网中使用
>   2.   客户端需要绑定服务器广播使用的端口，才可以接受到广播消息

-   int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen)
    -   功能：设置广播属性
    -   参数：
        -   sockfd：文件描述符
        -   level：SOL_SOCKET
        -   optname：SO_BROADCAST
        -   optval：int类型的值，为1表示允许广播
        -   optlen：optval的大小

## 组播（多播）

>   单薄地址表示单个IP接口，广播地址标识某个子网的所有IP接口，多播地址标识一组IP接口。单播和广播是寻址方案的两个极端，多播则意在两者之间提供一种这种方案。多播数据报只应该由对它感兴趣的接口接收，也就是说由运行相应多播会话应用系统的主机上的接口接受。另外，广播一般局限于局域网内使用，而多播则既可以用于局域网也可以跨广域网使用
>
>   1.   组播既可以用于局域网，也可以用于广域网
>   2.   客户端需要加入多播组，才能接受到多播的数据

-   用setsockopt实现，
    -   服务端设置多播信息，外出接口
        -   level：IPPROTO_IP
        -   optname：IP_MULTICAST_IF
        -   optval：struct in_addr
    -   客户端加入到多播组
        -   level：IPPROTO_IP
        -   optname：IP_ADD_MEMBERSHIP
        -   optval：struct mreq

## 本地套接字

>   -   **作用**：本地的进程间通信
>
>       ​	有关系的进程间的通信
>
>       ​	没有关系的进程间的通信
>
>       本地套接字实现流程和网络套接字类似，一般采用TCP的通信流程
>
>   -   流程：
>
>       **要用unlink删除掉客户端和服务端产生的用于通信的伪文件**
>
>       -   服务端：
>
>           1.   创建监听的套接字
>
>                int lfd = socket(AF_UNIX / PF_LOCAL, SOCK_STREAM, 0)
>
>           2.   监听的套接字绑定本地的套接字文件 -> server端
>
>                struct sockaddr_un addr
>
>                **//绑定成功后，指定的sun_path中的套接字文件会自动生成**
>
>                bind(lfd, addr, len)
>
>           3.   监听
>
>                listen(lfd, 100)
>
>           4.   等待并接受连接请求
>
>                struct sockaddr_un cliaddr
>
>                int cfd = accept(lfd, &cliaddr, len)
>
>           5.   通信
>
>                ​	接受数据：read / recv
>
>                ​	发送数据：write / send
>
>           6.   关闭连接
>
>                close()
>
>       -   客户端：
>
>           1.   创建通信的套接字
>
>                int fd = socket(AF_UNIX / AF_LOCAL, SOCK_STREAM, 0)
>
>           2.   监听的套接字绑定本地的IP和端口
>
>                struct sockaddr_un addr
>
>                **//绑定成功后，指定的sun_path中的套接字文件会自动生成**
>
>                bind(lfd, addr, len)
>
>           3.   连接服务器
>
>                struct sockaddr_un serveraddr
>
>                connect(fd, &serveraddr, sizeof(serveraddr))
>
>           4.   通信
>
>                ​	接受数据：read / recv
>
>                ​	发送数据：write / send
>
>           5.   关闭连接
>
>                close()

![image-20220323212332204](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203232123278.png)

# 阻塞 / 非阻塞、同步 / 异步（网络IO）

>   典型的一次IO的两个阶段：数据就绪和数据读写
>
>   数据就绪：根据系统IO操作的就绪状态
>
>   -   阻塞
>   -   非阻塞
>
>   数据读写：根据应用程序和内核的交互方式
>
>   -   同步
>   -   异步

# Unix/Linux上的五种IO模型

## 阻塞blocking

>   调用者调用了某个函数,等待这个函数返回,期间什么也不做,不停的去检查这个函数是否返回,必须等待这个函数返回才能进行下一步动作

![image-20220324092510744](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203240925676.png)

## 非阻塞 non-blocking

>   非阻塞等待,每隔一段时间就去检测IO时间是否就绪.没有就绪就可以做其他事.非阻塞I / O 执行系统调用总是立即返回,不管事件是否已经发生,若时间没有发生,则返回-1,此时可以根据errno区分这两种情况,对于accept,recv和send,事件未发生时,errno通常被设置未EAGAIN

![image-20220324093125392](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203240931905.png)

## IO复用

>   Linux用select / poll / epoll 函数实现IO服用模型,这些函数也会使进程阻塞,但是和阻塞IO所不同的是这些函数可以同时阻塞多个IO操作.而且可以同时对多个读操作\写操作的IO函数进行检测.直到有数据可读或可写时,才真正调用IO操作函数

![image-20220324094013872](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203240940410.png)

## 信号驱动

>   Linux用套接口进行信号驱动IO,安装一个信号处理函数,进程继续运行并不阻塞,当IO事件就绪,进程收到SIGIO信号然后处理IO事件
>
>   **内核在第一个阶段是异步,在第二个阶段是同步;与非阻塞IO的区别在于它提供了消息通知机制,不需要用户进程不断地轮询检查,减少了系统API地调用次数,提高了效率**

![image-20220324094644327](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203240946731.png)

## 异步

>   Linux中,可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区地大小\文件偏移以及通知地方式,然后立即返回,当内核将数据拷贝到缓冲区后,再通知应用程序

![image-20220324095659171](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203240956629.png)

# Web Server(网页服务器)

>   一个Web Server就是一个服务器软件(程序), 或者是运行这个服务器软件地硬件(计算机).其主要功能是通过HTTP协议与客户端(通常是兰奇(Browser)进行通信,来接受,存储,处理来自客户端地HTTP请求,并对其做出HTTP响应,返回给客户端其请求地内容(文件/网页等)或返回一个Error信息
>
>   ![image-20220324100240432](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203241002772.png)
>
>   通常用户使用Web浏览器与相应服务器进行通信.在浏览器中键入"域名"或"IP地址:端口号",浏览器则先将你地域名解析成相应地IP地址或者直接根据你的IP地址向对应的Web服务器发送一个HTTP请求.这一过程首先要通过TCP协议的三次握手建立与目标Web服务器的连接,然后HTTP协议生成针对目标Web服务器的HTTP请求报文,通过TCP\IP等协议发送到目标Web服务器上

## HTTP协议(应用层的协议)

### 简介

超文本传输协议(HTTP)是一个简单的请求 - 响应协议,它通常运行在TCP之上.它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应.请求和响应信息的头以ASCII形式给出;而消息内容则具有一个类似MIME的格式.HTTP是万维网的数据通信的基础.

### 概述

HTTP是一个客户端终端(用户)和服务端(网站)请求和应答的标准(TCP).通过使用网页浏览器/网络爬虫或者其他的工具,客户端发起一个HTTP请求到服务器上指定端口(默认端口80).我们就称这个客户端为用户代理程序.应答的服务器上存储着一些资源,比如HTML文件和图像.我们称这个应答服务器为源服务器.在用户代理和源服务器中间可能存在多个中间层,比如代理服务器/网关或者隧道

尽管TCP/IP协议是互联网上最流行的应用,HTTP协议中,并没有规定必须使用它或它支持的层.事实上,HTTP可以在任何互联网协议上,或其他网络上实现.HTTP假定其下层协议提供可靠的传输.因此,任何能够提供这种保证的协议都可以被其使用.因此也就是其在TCP/IP协议族使用TCP作为其传输层

### 发展历史

| 版本     | 产生时间 | 内容                                                         | 发展现状           |
| -------- | -------- | ------------------------------------------------------------ | ------------------ |
| HTTP/0.9 | 1991     | 不涉及数据包传输，规定客户端和服务器之间通信格式，只能GET请求 | 没有作为正式标准   |
| HTTP/1.0 | 1996     | 传输内容格式不限制，增加PUT、PATCH、HEAD、OPTIONS、DELETE命令 | 正式作为标准       |
| HTTP/1.1 | 1997     | 持久连接（长连接）、节约带宽、HOST域、管道机制、分块传输编码 | 2015年前使用最广泛 |
| HTTP/2   | 2015     | 多路复用、服务器推送、头信息压缩、二进制协议                 | 逐渐覆盖市场       |

-   **多路复用**：通过单一的HTTP/2连接请求发起多重的请求-响应消息，多个请求stream共享一个TCP连接，实现多留并行而不是依赖建立多个TCP连接。

![image-20220405213831888](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204052138983.png)



### 工作原理

HTTP协议定义Web客户端如何从Web服务器请求Web页面,以及服务器如何把Web传送给客户端.HTTP协议采用了请求 / 响应模型. 客户端向服务器发送一个请求报文,请求报文包含请求的方法/URL/协议版本/请求头部和请求数据.服务器以一个状态行作为响应,响应的内容包括协议的版本/成功或者错误代码/服务器信息/响应头部和响应数据

### **步骤**

1.   客户端连接到Web服务器

     一个HTTP客户端,通常是浏览器,与Web服务器的HTTP端口(默认是80)建立一个TCP套接字连接

2.   发送HTTP请求

     通过TCP套接字,客户端向Web服务器发送一个问题的请求报文,一个请求报文由请求行\请求头部\空行和请求数据4个部分组成

3.   服务器接受请求并返回HTTP响应

     Web服务器解析请求,定位请求资源.服务器将资源复本写到TCP套接字,由客户端读取.有一个响应由状态行\响应头部\空行和响应数据4部分组成

4.   释放连接TCP连接

     若connection模式为close,则服务器主动关闭TCP连接,客户端被动关闭连接,释放TCP连接;若connection模式为keepalive,则该连接会保持一段事件,在该事件内可以继续接收请求

5.   客户端浏览器解析HTML内容

     客户端浏览器首先解析状态行,查看表明请求是否成功的状态代码.然后解析每一个响应头,响应头告知以下为若干字节的HTML文档和文档的字符集.客户端浏览器读取响应数据HTML,根据HTML的语法对其进行格式化,并在浏览器窗口中显示

>   **HTTP协议是基于TCP/IP协议之上的应用层协议,基于请求-响应的模式.HTTP协议规定,请求从客户端发出,最后服务器端响应请求并返回.换句话说,肯定是先从客户端开始建立通信的,服务器端在没有接收到请求之前不会发送响应**

### HTTP 请求报文格式

![image-20220324111933648](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203241119578.png)

### HTTP响应报文格式

![image-20220324112009534](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203241120997.png)

### HTTP请求方法(8种)

1.   GET

     向指定的资源发出“显示”请求。使用GET方法应该只用在读取数据，而不应当被用于产生“副作用”的操作种。其中一个原因是GET可能会被网络蜘蛛等随意访问

2.   HEAD

     与GET方法一样，都是向服务器发出指定资源的请求。只不过服务器将不传回资源的本文部分。它的好处在于，使用这个方法可以在不必传输全部内容的情况下，就可以获取其中“关于该资源的信息”（元信息或元数据）

3.   POST

     向指定资源提交数据，请求服务器进行处理（例如提交表单或上传文件）。数据被包含在请求本文中。这个请求可能会创建新的资源或修改现有资源，或两者皆有。

4.   PUT

     向指定资源位置上传其最新内容

5.   DELETE

     请求服务器删除Request-URI所标识的资源

6.   TRACE

     回显服务器收到的请求，主要用于测试或诊断

7.   OPTIONS

     这个方法可使服务器传回该资源所支持的所有HTTP请求方法。用‘\*’来代替资源名称，向web服务器发送OPTIONS请求，可以测试服务器功能是否正常运作

8.   CONNECT

     预留给能够将连接改为管道方式的代理服务器。通常用于SSL加密服务器的链接（经由非加密的HTTP代理服务器）

## HTTPS

**TSL四次握手在TCP三次握手之后，因为要先建立可靠的连接（三次握手的时候不带信息）**

### 概况

>   HTTPS（全称：Hyper Text Transfer Protocol over Secure Socket Layer 或 Hypertext Transfer Protocol Secure，超文本传输安全协议），是以安全为目标的 HTTP 通道，简单讲是 HTTP 的安全版。即 HTTP 下加入 SSL 层，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL。 它是一个 URI scheme（抽象标识符体系），句法类同 http: 体系。用于安全的 HTTP 数据传输。https: URL 表明它使用了 HTTP，但 HTTPS 存在不同于 HTTP 的默认端口及一个加密/身份验证层（在 HTTP 与 TCP 之间）。
>
>   WEB 服务存在 http 和 https 两种通信方式，http 传输不加密，默认采用 80 作为通讯端口；https 对传输的数据进行加密，默认采用 443 端口。目前主流的网站基本上开始默认采用 HTTPS 作为通信方式。
>
>   SSL/TLS 是一个密码学协议，它的目标并不仅仅是网页内容的加密传输。SSL/TLS 的主要目标有四个：加密安全、互操作性、可扩展性和效率。对于安全性的保障，它还会从多个方面进行，包括机密性，真实性以及完整性。机密性是指，传输的内容不被除通信的双方外的第三方获取；真实性是指，通信的对端正是期待的对端，而不是其它第三方冒充的；完整性则是指，传输的数据是完整的，数据没有被篡改或丢失。为了平衡多种需求，SSL/TLS被设计为一个安全框架，其中可以应用多种不同的安全方案，每种方案都由多个复杂的密码学过程组成。不同的安全方案，在安全性和效率之间有着不同的取舍，并由不同的密码学过程组成。

### 对称加密

对称加密算法的加密和解密都是用同一个密钥。

如果通信双方都各自持有同一个密钥，且没有别人知道，则两方的通信安全是可以被保证的（除非密钥被破解）。然而，最大的问题就是这个密钥怎么让传输的双方知晓，同时不被别人知道。如果由服务器生成一个密钥并传输给浏览器，这个传输过程中密钥被别人劫持，之后他就能用密钥解开双方传输的任何内容。

如果浏览器内部预存了网站 A 的密钥，且可以确保除了浏览器和网站 A，不会有任何外人知道该密钥，那理论上用对称加密是可以的。这样，浏览器只要预存好世界上所有 HTTPS 网站的密钥就可以了。显然，这样做是不现实的。

![image-20220406003155687](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204060031760.png)

### 非对称加密

基于对称加密存在的问题，又有了非对称加密。非对称加密算法需要一组密钥对，分别是公钥和私钥，这两个密钥是成对出现的。公钥加密的内容需要对应的私钥解密，私钥加密的内容需要对应的公钥解密。私钥由服务器自己保存，公钥发送给客户端。客户端拿到公钥后可以对请求进行加密后发送给服务端，这时候就算中间被截获，没有私钥也无法解密发送的内容，这样确保了客户端发送到服务端数据的安全。

![image-20220406003251101](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204060032163.png)

### 非对称加密改良方案

通过一组公钥私钥，已经可以保证单个方向传输的安全性，那用两组公钥私钥，是不是就能保证双向传输都安全了？请看下面的过程：

1.   某网站拥有用于非对称加密的公钥 A1、私钥 A2；浏览器拥有用于非对称加密的公钥 B1、私钥 B2。
2.   浏览器向网站服务器请求，服务器把公钥 A1 明文传输给浏览器。
3.   浏览器把公钥 B1 明文传输给服务器。
4.   之后浏览器向服务器传输的所有东西都用公钥A1加密，服务器收到后用私钥 A2 解密。由于只有服务器拥有私钥 A2 进行解密，所以能保证这条数据的安全。
5.   服务器向浏览器传输的所有东西都用公钥 B1 加密，浏览器收到后用私钥 B2 解密。同上也可以保证这条数据的安全。
6.   可见确实可行。抛开这里面仍有的漏洞不谈（中间人攻击，下文会讲），HTTPS 的加密却没使用这种方案，为什么？最主要的原因是非对称加密算法非常耗时，特别是加密解密一些较大数据的时候有些力不从心。而对称加密快很多。

![image-20220406003445401](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204060034471.png)

### 非对称加密 + 对称加密

既然非对称加密耗时，我们考虑是否可以采用非对称加密+对称加密结合的方式，而且要尽量减少非对称加密的次数。

非对称加密、解密各只需一次的方法：

1.   某网站拥有用于非对称加密的公钥 A1、私钥 A2。
2.   浏览器向网站服务器请求，服务器把公钥 A1 明文给传输浏览器。
3.   浏览器随机生成一个用于对称加密的密钥 X，用公钥 A1 加密后传给服务器。
4.   服务器拿到后用私钥 A2 解密得到密钥 X。
5.   这样双方就都拥有密钥 X 了，且别人无法知道它。之后双方所有数据都用密钥 X 加密解密即可。

HTTPS 基本就是采用了这种方案。但还是有漏洞的。

![image-20220406004433872](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204060044940.png)

### 中间人攻击

中间人的确无法得到浏览器生成的对称密钥 X，这个密钥本身被公钥 A1 加密，只有服务器才能用私钥 A2 进行解密。然而中间人却完全不需要拿到私钥 A2 就能劫持信息，请看：

1.   某网站拥有用于非对称加密的公钥 A1、私钥 A2。
2.   浏览器向网站服务器请求，服务器把公钥 A1 明文传输给浏览器。
3.   中间人劫持到公钥 A1，保存下来，把数据包中的公钥 A1 替换成自己伪造的公钥 B1（它当然也拥有公钥 B1 对应的私钥 B2）。
4.   浏览器随机生成一个用于对称加密的密钥 X，用公钥 B1（浏览器不知道公钥被替换了）加密后传给服务器。
5.   中间人劫持后用私钥 B2 解密得到密钥 X，再用公钥 A1 加密后传给服务器。
6.   服务器拿到后用私钥 A2 解密得到密钥 X。
7.   **这样在双方都不会发现异常的情况下，中间人得到了对称密钥 X，再使用对称密钥 X 进行传输数据肯定是不安全了。根本原因是浏览器无法确认自己收到的公钥是不是网站自己的。那么下一步就是解决这个问题：如何证明浏览器收到的公钥一定是该网站的公钥？**

例子：

>   这就好比是，骗子在同学参加四、六级考试的时候，给同学的家长打电话或发短信，声称自己是学校的辅导员，并表示同学病重急需用钱，要求家长汇钱，同学家长汇钱给骗子而遭受巨大损失的情况。这就是数据/信息真实性没有得到足够验证而产生的问题。
>
>   再比如，一个仿冒的 taobao 网站，域名与真实的网站非常相似。我们一不小心输错了域名，或域名被劫持而访问了这个仿冒的网站，然后像平常在 taobao 购物一样，选择宝贝，并付款，但最后却怎么也收不到货物。

![image-20220406005116549](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204060051619.png)

### 数字证书

>   现实生活中，如果想证明某身份证号一定是小明的，怎么办？看身份证。这里政府机构起到了“公信”的作用，身份证是由它颁发的，它本身的权威可以对一个人的身份信息作出证明。互联网中也有这么一个公信机构，CA 机构。
>
>   网站在使用 HTTPS 前，需要向“CA机构”申请颁发一数字证书，数字证书里有证书持有者、证书持有者的公钥等信息，类似如下（实际上就是一堆数据，这里为了直观）。服务器把证书传输给浏览器，浏览器从证书里取公钥就可以了。然而这里又有一个显而易见的问题：证书本身的传输过程中，如何防止被篡改？即如何证明证书本身的真实性？数字证书怎么防伪呢？
>
>   CA 机构就是数字证书颁发的权威机构，负责颁发证书以及验证证书的合法性。如果服务器需要做个有身份的服务器，就需要向 CA 机构提交申请，当然有钱才好办事，交钱才能给你办证……
>
>   服务器向 CA 机构提交申请，需要提交站点的信息如域名、公司名称、公钥等等，CA 审批无误之后就可以给服务器颁发证书了！
>
>   客户端在拿到服务器的证书后，就需要验证证书编号是否能在对应的 CA 机构查到，并且核对证书的基本信息如证书上的域名是否与当前访问的域名一致等等，还可以拿到证书中服务器的公钥信息用于协商对称密钥！
>
>   证书颁发了，可是又怎么防止伪造，怎么保证在传输过程中不被篡改呢？即如何证明证书本身的真实性？数字证书怎么防伪呢？

![image-20220406011339597](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204060113676.png)

### 数字签名

>   我们把证书内容生成一份“签名”，比对证书内容和签名是否一致就能察觉是否被篡改。这种技术就叫数字签名。
>
>   数字签名的制作过程：
>
>   CA 拥有非对称加密的私钥和公钥。
>   CA 对证书明文信息进行 hash。
>   对 hash 后的值用私钥加密，得到数字签名。
>   明文和数字签名共同组成了数字证书，这样一份数字证书就可以颁发给网站了。那浏览器拿到服务器传来的数字证书后，如何验证它是不是真的？（有没有被篡改、掉包）

-   数字签名制作过程

    ![image-20220406011633025](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204060116082.png)

-   数字签名验证过程

    ![image-20220406011642541](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204060116599.png)

浏览器验证过程：

1.   拿到证书，得到明文 T1，数字签名 S1。
2.   用 CA 机构的公钥对 S1 解密（由于是浏览器信任的机构，所以浏览器保有它的公钥。详情见下文），得到 S2。
3.   用证书里说明的 hash 算法对明文 T1 进行 hash 得到 T2。
4.   比较 S2 是否等于 T2，等于则表明证书可信。

### 为什么使用数字签名可以证明证书可信？

假设中间人篡改了证书的原文，由于他没有 CA 机构的私钥，所以无法得到此时加密后签名，无法相应地篡改签名。浏览器收到该证书后会发现原文和签名解密后的值不一致，则说明证书已被篡改，证书不可信，从而终止向服务器传输信息，防止信息泄露给中间人。

### 既然不可能篡改，那如果整个证书被掉包呢？

假设有另一个网站 B 也拿到了CA 机构认证的证书，它想搞垮网站 A，想劫持网站 A 的信息。于是它成为中间人拦截到了 A 传给浏览器的证书，然后替换成自己的证书，传给浏览器，之后浏览器就会错误地拿到 B 的证书里的公钥了，会导致上文提到的漏洞。

**其实这并不会发生，因为证书里包含了网站 A 的信息，包括域名，浏览器把证书里的域名与自己请求的域名比对一下就知道有没有被掉包了。**

### 制作数字签名时为什么需要 hash 一次

最显然的是性能问题，前面我们已经说了非对称加密效率较差，证书信息一般较长，比较耗时。而 hash 后得到的是固定长度的信息（比如用 md5 算法 hash 后可以得到固定的 128 位的值），这样加密解密就会快很多。当然除此之外也有安全上的原因。

### HTTPS 必须在每次请求中都要先在 SSL/TLS 层进行握手传输密钥吗

显然每次请求都经历一次密钥传输过程非常耗时，那怎么达到只传输一次呢？用session就可以。

服务器会为每个浏览器（或客户端软件）维护一个 session ID，在 TSL 握手阶段传给浏览器，浏览器生成好密钥传给服务器后，服务器会把该密钥存到相应的 session ID 下，之后浏览器每次请求都会携带 session ID，服务器会根据 session ID 找到相应的密钥并进行解密加密操作，这样就不必要每次重新制作、传输密钥了

### 工作流程

1.   client 向 server 发送请求 https://baidu.com，然后连接到 server 的 443 端口。

2.   服务端必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面，这套证书其实就是一对公钥和私钥。

3.   传送证书
     这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间、服务端的公钥，第三方证书认证机构(CA)的签名，服务端的域名信息等内容。

4.   客户端解析证书
     这部分工作是由客户端的 TLS 来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随机值（密钥）。然后用证书对该随机值进行加密。

5.   传送加密信息
     这部分传送的是用证书加密后的密钥（随机值），目的就是让服务端得到这个密钥（随机值），以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。

6.   服务端加密信息
     服务端用私钥解密，得到了客户端传过来的密钥（随机值），然后把内容通过该值进行对称加密。

7.   传输加密后的信息
     这部分信息是服务端用密钥（随机值）对称加密后的信息，可以在客户端被还原。

8.   客户端解密信息
     客户端用之前生成的密钥（随机值）解密服务端传过来的信息，于是获取了解密后的内容。

![image-20220406013332647](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204060133709.png)

## HTTP与HTTPS的区别

-   URL中的通信协议不一样

    URL分为两部分：通信协议和域名地址

    ![image-20220405212546698](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204052125778.png)

-   数据传输不同（网络结构不一样）

    HTTP是明文传输，没有任何加密

    HTTPS在HTTP的基础上加入了SSL / TLS协议（SSL / TLS依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密）

    ![image-20220405212905770](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202204052129834.png)

-   默认端口不同

    HTTP是80端口，HTTPS是443端口

-   搜索排名不同

    各大搜索引擎中，HTTPS网站比HTTP网站的搜索排名更有优势

## DNS



### 递归查询

一般客户机和服务器之间属递归查询，即当客户机向DNS服务器发出请求后,若DNS服务器本身不能解析，则会向另外的DNS服务器发出查询请求，得到结果后转交给客户机。

### 迭代查询（反复查询）

一般DNS服务器之间属迭代查询。DNS 服务器另外一种查询方式为迭代查询，DNS 服务器会向客户机提供其他能够解析查询请求的DNS 服务器地址，当客户机发送查询请求时，DNS 服务器并不直接回复查询结果，而是告诉客户机另一台DNS 服务器地址，客户机再向这台DNS 服务器提交请求，依次循环直到返回查询的结果为止。

## 服务器编程基本框架

**虽然服务器程序种类繁多，但其基本框架都一样，不同之处在于逻辑处理**

![image-20220324163750709](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203241637794.png)

| 模块         | 功能                       |
| ------------ | -------------------------- |
| I/O处理单元  | 处理客户连接，读写网络数据 |
| 逻辑单元     | 业务进程或线程             |
| 网络存储单元 | 数据库、文件或缓存         |
| 请求队列     | 各单元之间的通信方式       |

>   I / O处理单元是服务器管理客户连接的模块。它通常要完成以下工作：等待并接受新的客户连接，接受客户数据，将服务器响应数据返回给客户端。但数据的收发不一定在I/O处理单元中执行，也可能在逻辑单元中执行，具体在何处执行取决于事件处理模式
>
>   一个逻辑单元通常是一个进程或线程。它分析并处理客户数据，然后将结果传递给I/O处理单元或者直接发送给客户端（具体使用哪种方式取决于事件处理模式）。服务器通常拥有多个逻辑单元，以实现对多个客户任务的并发处理。
>
>   网络存储单元可以是数据库、缓存和文件，但不是必须的
>
>   请求队列是各单元之间的通信方式的抽象。I/O处理单元接受到客户请求时，需要以某种方式通知一个逻辑单元来处理该请求。同样，多个逻辑单元同时访问一个存储单元时，也需要采用某种机制来协调处理竞态条件。请求队列通常被实现为池的一部分。

### 两种高效的事件处理模式（Reactor、Proactor）

服务器程序通常需要处理三类事件：I/O事件、信号以及定时事件。有两种高效的事件处理模式：Reactor和Proactor，同步I/O模型通常用于实现Reactor模式，异步I/O模型通常用于实现Proactor模式

### Reactor模式

要求主线程(I/O处理单元)只负责监听文件描述符上是否有事件发生，有的话就立即将该事件通知工作线程（逻辑单元），将socket可读可写事件放入请求队列，交给工作线程处理。除此之外，主线程不做任何其他实质性的工作。读写数据，接受新的连接，以及处理客户端请求均在工作线程中完成。

使用同步I/O模拟（以epoll_wait为例）实现的Reactor模式的工作流程是：

1.   主线程往epoll内核事件表中注册socket上的读就绪事件
2.   主线程调用epoll_wait等待socket上有数据可读
3.   当socket上有数据可读时，epoll_wait通知主线程。主线程则将socket可读事件放入请求队列。
4.   睡眠在请求队列上的某个工作线程被唤醒，它从socket读取数据，并处理客户请求，然后往epoll内核事件表中注册该socket上的写就绪事件
5.   当主线程调用epoll_wait等待socket可写
6.   当socket可写时，epoll_wait通知主线程。主线程将socket可写事件放入请求队列
7.   睡眠在请求队列上的某个工作线程被唤醒，它往socket写入服务器处理客户端请求的结果	

![image-20220324173124868](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203241731927.png)

### Proactor模式(异步)

Proactor模式将所有I/O操作都交给主线程和内核来处理（进行读、写），工作线程仅仅负责业务逻辑。使用异步I/O模型（以aio_read和aio_write为例）实现的Proactor模式的工作流程是:

1.   主线程调用aio_read函数向内核注册socket上的读完成事件，并告诉内核用户读缓冲区的位置，以及读操作完成时如何通知应用程序（这里以信号为例）
2.   主线程继续处理其他逻辑
3.   当socket上的数据被读入用户缓冲区后，内核将向应用程序发送一个信号，以通知应用程序数据已经可用
4.   应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。工作线程处理完客户请求后，调用aio_write函数向内核注册socket上的写完成事件，并告诉内核用户写缓冲区的位置，以及写操作完成时如何通知应用程序
5.   主线程继续处理其他逻辑
6.   当用户缓冲区的输入被写入socket之后，内核将向应用程序发送一个信号，以通知应用程序数据已经发送完毕
7.   应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理，比如决定是否关闭socket

![image-20220324173505222](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203241735278.png)

### 模拟Proactor模式(同步I/O)

使用同步I/O方式模拟出Proactor模式。原理是：主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一“完成事件“。那么从工作线程的角度来看，它们就直接获得了数据读写的结果，接下来要做的只是对读写的结果进行逻辑处理。

使用同步I/O模型（以epoll_wait为例）模拟出的Proactor模式的工作流程如下：

1.   主线程往epoll内核事件表中注册socket上的读就绪事件
2.   主线程调用epoll_wait等待socket上有数据可读
3.   当socket上有数据可读时，epoll_wait通知主线程。主线程从socket循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列
4.   睡眠在请求队列上的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件
5.   主线程调用epoll_wait等待socket可写
6.   当socket可写时，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果

![image-20220324174606909](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203241746983.png)

### 线程池

线程池是由服务器预先创建的一组子线程，线程池中的线程数量应该和CPU数量差不多。线程池中的所有子线程都运行着相同的代码。当有新的任务到来时，主线程将通过某种方式选择线程池中的某个子线程来为之服务。相比与动态的创建子线程，选择一个已经存在的子线程的代价显然要小得多。至于主线程选择哪个子线程来为新任务服务，则有多种方式：

-   主线程使用某种算法来主动选择子线程。最简单、最常用的算法就是随机算法和Round Robin（轮流选取）算法，但更优秀、更智能的算法将使任务在各个工作线程中更均匀地分配，从而减轻服务器的整体压力
-   主线程和所有主线程通过一个共享的工作队列来同步，子线程都睡眠在该工作队列上。当有新的任务到来时，主线程将任务添加到工作队列中。这将换唤醒正在等待任务的子线程，不过只有一个子线程将获得新任务的”接管权“，它可以从工作队列中取出任务并执行之，而其他子线程将继续睡眠在工作队列中

线程池一般模型：

![image-20220324175331789](https://raw.githubusercontent.com/WinnieVenice/PicBed/main/202203241753837.png)

>   线程池中的线程数量最直接的限制因素是CPU的处理器(cores)数量:
>
>   如果你的CPU是4-cores的,对于CPU密集型的任务(如视频剪辑等消耗CPU计算资源的任务)来说,那线程池中的线程数量最好也设置为4(或+1防止其他因素造成的线程阻塞);对于IO密集型的任务,一般要多于CPU的核心数,因为线程间竞争的不是CPU的计算资源而是IO,IO的处理一般较慢,多于cores数的线程将为CPU争取更多的任务,不至在线程处理IO的过程造成CPU空闲导致资源浪费.

-   空间换时间,浪费服务器的硬件资源,换取运行效率
-   池是一组资源的集合,这组资源在服务器启动之初就被完全创建好并初始化,这称为静态资源
-   当服务器进入正式运行阶段,开始处理客户请求的时候,如果它需要相关的资源,可以直接从池中获取,无需动态分配
-   当服务器处理完一个客户连接后,可以把相关的资源放回池中,无需执行系统调用释放资源

### EPOLLONESHOT事件(解决并发问题)

**即使可以使用ET模式,一个socket上的某个事件还是可能被触发多次.这在并发程序中就会引起一个问题**.比如一个线程在读取完某个socket上的数据后开始处理这些数据,而在数据的处理过程中该socket上又有新数据可读(EPOLLIN再次被触发),此时另外一个线程被唤醒来读取这些新数据.于是就出现了两个线程同时操作一个socket的局面.一个socket连接在任一时刻都只被一个线程处理,可以使用epoll的EPOLLONESHOT事件实现.

对于注册了EPOLLONESHOT事件的文件描述符,操作系统最多触发其上注册的一个可读\可写或者异常事件,且只触发一次,除非我们使用epoll_ctl函数重置该文件描述符上注册的EPOLLONESHOT事件.这样,当一个线程在处理某个socket时,其他线程是不可能有机会操作该socket的.但反过来思考,注册了EPOLLONESHOT事件的socket一旦被某个线程处理完毕,该线程就应该立即重置这个socket上的EPOLLONESHOT事件,以确保这个socket下一次可读时,其EPOLLIN事件能被触发,进而让其他工作线程有机会继续处理这个socket.

### 有限状态机(解析HTTP)

逻辑单元内部的一种高效编程方式：有限状态机

有的应用层协议头部包含数据包类型字段，每种类型可以映射为逻辑单元的一种执行状态，服务器可以根据它来编写相应的处理逻辑。

### 服务器压力测试Webbench

Webbench是Linux上一款知名的、优秀的web性能压力测试工具

-   测试出在相同硬件上，不同服务的性能以及不同硬件巡航同一个服务的运行情况
-   展示服务器的两项内容：每秒钟响应请求数和每秒钟传输数据量

基本原理：

>   Webbench首先fork出多个子进程，每个子进程都循环做web访问测试。子进程把访问的结果通过pipe告诉父进程，父进程做最终的统计结构

示例：

>   webbench -c 1000 -t 30 http://192.168.110.129:10000/index.html
>
>   参数：
>
>   ​	-c	表示客户端数
>
>   ​	-t	表示时间

## 浏览器输入URL到返回页面的全过程

​	1.根据域名，进行DNS域名解析；

​	2.拿到解析的IP地址，建立TCP连接；

​	3.向IP地址，发送HTTP请求；

​	4.服务器处理请求；

​	5.返回响应结果；

​	6.关闭TCP连接；

​	7.浏览器解析HTML；

​	8.浏览器布局渲染；

## 一个 TCP 连接可以对应几个 HTTP 请求？(提示，这在问你HTTP1.0和1.1的区别)

## 一个 TCP 连接中 HTTP 请求发送可以一起发送么（比如一起发三个请求，再三个响应一起接收）？(提示，这就是在问你HTTP2.0和HTTP1.1协议的区别)

## 浏览器对同一Host建立TCP连接到数量有没有限制？(拜托，一个网站那么多图片，开一个TCP连接，按顺序下载？那不是等到死？)

## 说说UDP协议在哪里使用，TCP协议在哪里使用？

域名解析用UDP

与服务器建立连接的时候用TCP还有区域传送用TCP

## 域名解析为什么用UDP？区域复制为什么用TCP？

-   域名解析为什么用UDP？

    UDP快，UDP的DNS协议只需要一个请求一个应答即可。而如果用TCP要三次握手、发送数据、应答、四次挥手。但UDP协议传输内容不超过512字节。不过客户端向DNS服务器查询域名一般返回的内容不超过512字节，所以可以用UDP传输

-   区域复制为什么用TCP？

    DNS规范了2种类型的DNS服务器，一种是主DNS服务器，一种是辅助DNS服务器。在一个区种主DNS服务器读取该区的DNS数据信息，当一个辅助DNS服务器启动时，它需要与主DNS服务器通信，并加载数据信息，这就叫区域传送。这种情况就使用TCP

    TCP协议可靠，传输的内容大

